{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9e3e2a61-2500-4f10-9091-992cc2485733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various modeling lessons and breakfast hours from DSI 523\n",
    "# https://medium.com/towards-data-science/loss-functions-and-their-use-in-neural-networks-a470e703f1e9\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanAbsoluteError\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/Huber\n",
    "# https://towardsdatascience.com/what-is-batch-normalization-46058b4f583"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9509e54f-20d0-4638-aebd-93d7a93be9f1",
   "metadata": {},
   "source": [
    "# Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b828ad9a-87a1-4fcc-ab0b-1a27c6ba6159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, VotingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, Huber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0ce27d-3d8f-42de-9ea2-616dbf621a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = pd.read_csv('../data/average/a_df.csv')\n",
    "h_df = pd.read_csv('../data/high/h_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16db770f-e93d-4bfb-9395-8176710ffbd9",
   "metadata": {},
   "source": [
    "# Average Cycling Performance\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab7c15d-bf3f-4083-b508-3cd326ce0bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>dt</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>bearing</th>\n",
       "      <th>time_diff_s</th>\n",
       "      <th>total_time_s</th>\n",
       "      <th>ele_diff_m</th>\n",
       "      <th>total_ele_change_m</th>\n",
       "      <th>lat_lon</th>\n",
       "      <th>dist_diff_km</th>\n",
       "      <th>total_dist_km</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>clouds</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-20 16:07:45+00:00</td>\n",
       "      <td>38.773466</td>\n",
       "      <td>-121.363686</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>1658333265</td>\n",
       "      <td>78</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(38.77346634864807, -121.36368582956493)</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>297.65</td>\n",
       "      <td>297.17</td>\n",
       "      <td>1019</td>\n",
       "      <td>39</td>\n",
       "      <td>282.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-20 16:07:46+00:00</td>\n",
       "      <td>38.773542</td>\n",
       "      <td>-121.363672</td>\n",
       "      <td>35.599998</td>\n",
       "      <td>1658333266</td>\n",
       "      <td>79</td>\n",
       "      <td>8.292053</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.200001</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>(38.77354153431952, -121.36367183178663)</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>297.65</td>\n",
       "      <td>297.17</td>\n",
       "      <td>1019</td>\n",
       "      <td>39</td>\n",
       "      <td>282.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-20 16:07:49+00:00</td>\n",
       "      <td>38.773630</td>\n",
       "      <td>-121.363682</td>\n",
       "      <td>35.200001</td>\n",
       "      <td>1658333269</td>\n",
       "      <td>82</td>\n",
       "      <td>-5.321180</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.399998</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>(38.77363029867411, -121.36368239298463)</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>297.65</td>\n",
       "      <td>297.17</td>\n",
       "      <td>1019</td>\n",
       "      <td>39</td>\n",
       "      <td>282.80</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-20 16:07:51+00:00</td>\n",
       "      <td>38.773789</td>\n",
       "      <td>-121.363733</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1658333271</td>\n",
       "      <td>83</td>\n",
       "      <td>-13.956066</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.200001</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>(38.77378871664405, -121.36373268440366)</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>297.67</td>\n",
       "      <td>297.17</td>\n",
       "      <td>1019</td>\n",
       "      <td>38</td>\n",
       "      <td>282.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-20 16:07:52+00:00</td>\n",
       "      <td>38.773786</td>\n",
       "      <td>-121.363766</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1658333272</td>\n",
       "      <td>83</td>\n",
       "      <td>-96.936537</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>(38.77378553152084, -121.36376612819731)</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>297.67</td>\n",
       "      <td>297.17</td>\n",
       "      <td>1019</td>\n",
       "      <td>38</td>\n",
       "      <td>282.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp   latitude   longitude  elevation          dt  \\\n",
       "0  2022-07-20 16:07:45+00:00  38.773466 -121.363686  35.799999  1658333265   \n",
       "1  2022-07-20 16:07:46+00:00  38.773542 -121.363672  35.599998  1658333266   \n",
       "2  2022-07-20 16:07:49+00:00  38.773630 -121.363682  35.200001  1658333269   \n",
       "3  2022-07-20 16:07:51+00:00  38.773789 -121.363733  35.000000  1658333271   \n",
       "4  2022-07-20 16:07:52+00:00  38.773786 -121.363766  35.000000  1658333272   \n",
       "\n",
       "   heart_rate    bearing  time_diff_s  total_time_s  ele_diff_m  \\\n",
       "0          78   0.000000            0             0    0.000000   \n",
       "1          79   8.292053            1             1   -0.200001   \n",
       "2          82  -5.321180            3             4   -0.399998   \n",
       "3          83 -13.956066            2             6   -0.200001   \n",
       "4          83 -96.936537            1             7    0.000000   \n",
       "\n",
       "   total_ele_change_m                                   lat_lon  dist_diff_km  \\\n",
       "0                 0.0  (38.77346634864807, -121.36368582956493)        0.0000   \n",
       "1                -0.2  (38.77354153431952, -121.36367183178663)        0.0084   \n",
       "2                -0.6  (38.77363029867411, -121.36368239298463)        0.0099   \n",
       "3                -0.8  (38.77378871664405, -121.36373268440366)        0.0181   \n",
       "4                -0.8  (38.77378553152084, -121.36376612819731)        0.0029   \n",
       "\n",
       "   total_dist_km    temp  feels_like  pressure  humidity  dew_point  clouds  \\\n",
       "0         0.0000  297.65      297.17      1019        39     282.80       1   \n",
       "1         0.0084  297.65      297.17      1019        39     282.80       1   \n",
       "2         0.0183  297.65      297.17      1019        39     282.80       1   \n",
       "3         0.0364  297.67      297.17      1019        38     282.43       1   \n",
       "4         0.0393  297.67      297.17      1019        38     282.43       1   \n",
       "\n",
       "   wind_speed  wind_deg  \n",
       "0        0.45       177  \n",
       "1        0.45       177  \n",
       "2        0.45       177  \n",
       "3        0.45       177  \n",
       "4        0.45       177  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acc5f0b-46be-4d35-87ce-5e50e80274f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## X, y, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1422d14a-0130-44c4-afe3-74ee147cd7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'latitude', 'longitude', 'elevation', 'dt', 'heart_rate',\n",
       "       'bearing', 'time_diff_s', 'total_time_s', 'ele_diff_m',\n",
       "       'total_ele_change_m', 'lat_lon', 'dist_diff_km', 'total_dist_km',\n",
       "       'temp', 'feels_like', 'pressure', 'humidity', 'dew_point', 'clouds',\n",
       "       'wind_speed', 'wind_deg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7112d65-747f-47d3-a69d-5a905518bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_features = ['elevation', 'bearing', 'time_diff_s', 'total_time_s', 'ele_diff_m',\n",
    "       'total_ele_change_m', 'dist_diff_km', 'total_dist_km',\n",
    "       'temp', 'feels_like', 'pressure', 'humidity', 'dew_point', 'clouds',\n",
    "       'wind_speed', 'wind_deg']\n",
    "a_X = a_df[a_features]\n",
    "a_y = a_df['heart_rate']\n",
    "\n",
    "a_X_train, a_X_test, a_y_train, a_y_test = train_test_split(a_X, a_y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b0ddc5-1911-439c-89ec-342d06ab9dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130.21652421652422"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eab97a-12cc-46e7-b1bb-b0222df5cd69",
   "metadata": {},
   "source": [
    "### StandardScaler X_train and X_test for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8902c045-7211-4157-9248-2fb9e0426418",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ss = StandardScaler()\n",
    "a_X_train_sc = a_ss.fit_transform(a_X_train)\n",
    "a_X_test_sc = a_ss.transform(a_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b67ac0-6d16-4efe-b05c-b03bcea45e88",
   "metadata": {},
   "source": [
    "### Polynomial X_train and X_test for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f429dcf-6b97-424d-ac99-0f12184d3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_poly = PolynomialFeatures()\n",
    "a_X_train_sc_p = a_poly.fit_transform(a_X_train_sc)\n",
    "a_X_test_sc_p = a_poly.fit_transform(a_X_test_sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c0a5a-9580-4cb1-8a6b-d50c38e4879a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2308b699-e547-4eb1-914d-5d06f13712bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Train Score: 0.5260233155015783\n",
      "Linear Regression Test Score: 0.5322513167399172\n"
     ]
    }
   ],
   "source": [
    "a_lr = LinearRegression()\n",
    "a_lr.fit(a_X_train_sc, a_y_train)\n",
    "print(f'Linear Regression Train Score: {a_lr.score(a_X_train_sc, a_y_train)}')\n",
    "print(f'Linear Regression Test Score: {a_lr.score(a_X_test_sc, a_y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3eba4a-d843-40fe-894f-437fc51e4da6",
   "metadata": {},
   "source": [
    "### Linear Regression Pipeline (StandardScaler, Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dbc010d-fd67-4801-ad74-b6108a94f87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Pipe Train Score: 0.8082482755481244\n",
      "LR Pipe Test Score: 0.7906546450250773\n"
     ]
    }
   ],
   "source": [
    "a_lr_pipe = Pipeline([\n",
    "    ('a_ss', StandardScaler()),\n",
    "    ('a_poly', PolynomialFeatures()),\n",
    "    ('a_lr', LinearRegression())\n",
    "])\n",
    "\n",
    "a_lr_pipe.fit(a_X_train, a_y_train)\n",
    "print(f'LR Pipe Train Score: {a_lr_pipe.score(a_X_train, a_y_train)}')\n",
    "print(f'LR Pipe Test Score: {a_lr_pipe.score(a_X_test, a_y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3242f8-96db-41b8-9fca-e0b32a8aa4cc",
   "metadata": {},
   "source": [
    "### AdaBoost with Linear Regression Base Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "968bf2bf-2df7-48f1-9bfc-0f59053ef06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada LR Train Score: 0.8046423913777858\n",
      "Ada LR Test Score: 0.776694380832758\n"
     ]
    }
   ],
   "source": [
    "a_ada_lr = AdaBoostRegressor(base_estimator = LinearRegression(), random_state = 42)\n",
    "\n",
    "a_ada_lr.fit(a_X_train_sc_p, a_y_train)\n",
    "print(f'Ada LR Train Score: {a_ada_lr.score(a_X_train_sc_p, a_y_train)}')\n",
    "print(f'Ada LR Test Score: {a_ada_lr.score(a_X_test_sc_p, a_y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dcc69d-c9c3-47cb-a6e9-a1e24411836d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AdaBoost with Decision Tree Base Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc0afdc7-652b-4526-a213-bfca4d321bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868164587298871\n",
      "{'base_estimator__max_depth': 5, 'n_estimators': 200}\n",
      "Ada DT Train Score: 0.8756108134812447\n",
      "Ada DT Test Score: 0.8730399805443708\n"
     ]
    }
   ],
   "source": [
    "a_ada_dt = AdaBoostRegressor(base_estimator = DecisionTreeRegressor(), random_state = 42)\n",
    "\n",
    "a_ada_dt_params = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'base_estimator__max_depth': [1, 2, 5]\n",
    "}\n",
    "\n",
    "a_gs_ada_dt = GridSearchCV(a_ada_dt, param_grid = a_ada_dt_params, cv = 5)\n",
    "a_gs_ada_dt.fit(a_X_train_sc, a_y_train)\n",
    "print(a_gs_ada_dt.best_score_)\n",
    "print(a_gs_ada_dt.best_params_)\n",
    "print(f'Ada DT Train Score: {a_gs_ada_dt.score(a_X_train_sc, a_y_train)}')\n",
    "print(f'Ada DT Test Score: {a_gs_ada_dt.score(a_X_test_sc, a_y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6155407f-7539-4cbe-bca7-8b766fd70b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AdaBoost with Random Forest Base Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de35077-25ad-44a6-bb79-dc018699bd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844253394135492\n",
      "{'base_estimator__max_depth': 5, 'n_estimators': 50}\n",
      "Ada DT Train Score: 0.8526320077631239\n",
      "Ada DT Test Score: 0.8512220020729748\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "a_ada_rf = AdaBoostRegressor(base_estimator = RandomForestRegressor(), random_state = 42)\n",
    "\n",
    "a_ada_rf_params = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'base_estimator__max_depth': [1, 2, 5]\n",
    "}\n",
    "\n",
    "a_gs_ada_rf = GridSearchCV(a_ada_rf, param_grid = a_ada_rf_params, cv = 5)\n",
    "a_gs_ada_rf.fit(a_X_train_sc, a_y_train)\n",
    "print(a_gs_ada_rf.best_score_)\n",
    "print(a_gs_ada_rf.best_params_)\n",
    "print(f'Ada DT Train Score: {a_gs_ada_rf.score(a_X_train_sc, a_y_train)}')\n",
    "print(f'Ada DT Test Score: {a_gs_ada_rf.score(a_X_test_sc, a_y_test)}')\n",
    "'''\n",
    "'''\n",
    "0.844253394135492\n",
    "{'base_estimator__max_depth': 5, 'n_estimators': 50}\n",
    "Ada DT Train Score: 0.8526320077631239\n",
    "Ada DT Test Score: 0.8512220020729748\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8ca1c8-b384-47d3-996b-6f29e207438b",
   "metadata": {},
   "source": [
    "## Neural Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "72562d7c-5ea8-442a-9d86-9e02f13c5004",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_X_nn = a_df[a_features]\n",
    "a_y_nn = a_df['heart_rate']\n",
    "\n",
    "a_X_nn = np.array(a_X_nn)\n",
    "a_y_nn = np.array(a_y_nn)\n",
    "\n",
    "a_X_nn_train, a_X_nn_test, a_y_nn_train, a_y_nn_test = train_test_split(a_X_nn, a_y_nn, random_state = 42)\n",
    "\n",
    "a_ss_nn = StandardScaler()\n",
    "a_X_nn_train_sc = a_ss_nn.fit_transform(a_X_nn_train)\n",
    "a_X_nn_test_sc = a_ss.transform(a_X_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2407b7a2-6e73-4b0e-a006-93ffbc16cbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_X_nn[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ef54f2ba-d2bd-4c98-b754-af095d7e5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model_nn = Sequential()\n",
    "\n",
    "a_model_nn.add(Dense(128, input_dim = 16, activation = 'relu'))\n",
    "\n",
    "a_model_nn.add(BatchNormalization())\n",
    "a_model_nn.add(Dense(64, activation = 'relu', kernel_regularizer = l2(.05)))\n",
    "a_model_nn.add(Dense(128, activation = 'relu', kernel_regularizer = l2(.1)))\n",
    "a_model_nn.add(Dense(64, activation = 'relu', kernel_regularizer = l2(.05)))\n",
    "a_model_nn.add(Dense(128, activation = 'relu', kernel_regularizer = l2(.1))) #\n",
    "a_model_nn.add(Dense(64, activation = 'relu', kernel_regularizer = l2(.05))) #\n",
    "a_model_nn.add(Dense(1, kernel_regularizer = l2(.05)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d60e4577-0412-443b-94e0-ea16b121a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model_nn.compile(optimizer = 'adam', loss = 'mse', metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b676e67c-ea0c-4e85-88ea-8c8361d2fc68",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "354/354 [==============================] - 2s 3ms/step - loss: 1402.8568 - mse: 1375.6940 - val_loss: 916.9664 - val_mse: 891.9609\n",
      "Epoch 2/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 185.8377 - mse: 161.8447 - val_loss: 129.0215 - val_mse: 105.8657\n",
      "Epoch 3/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 163.9496 - mse: 141.4055 - val_loss: 120.2460 - val_mse: 98.2489\n",
      "Epoch 4/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 149.7216 - mse: 128.1440 - val_loss: 124.1007 - val_mse: 102.9350\n",
      "Epoch 5/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 132.7302 - mse: 111.9370 - val_loss: 149.5740 - val_mse: 129.1685\n",
      "Epoch 6/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 121.7645 - mse: 101.6487 - val_loss: 105.0668 - val_mse: 85.2323\n",
      "Epoch 7/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 124.3717 - mse: 104.8824 - val_loss: 96.6026 - val_mse: 77.4174\n",
      "Epoch 8/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 116.3999 - mse: 97.5006 - val_loss: 113.6389 - val_mse: 95.0095\n",
      "Epoch 9/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 113.5227 - mse: 95.1330 - val_loss: 113.0351 - val_mse: 94.9011\n",
      "Epoch 10/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 115.9556 - mse: 98.0479 - val_loss: 84.3727 - val_mse: 66.6805\n",
      "Epoch 11/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 104.4168 - mse: 86.9617 - val_loss: 100.4631 - val_mse: 83.2361\n",
      "Epoch 12/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 103.4460 - mse: 86.4242 - val_loss: 92.7243 - val_mse: 75.9222\n",
      "Epoch 13/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 99.8734 - mse: 83.2617 - val_loss: 130.8809 - val_mse: 114.5023\n",
      "Epoch 14/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 98.2274 - mse: 82.0262 - val_loss: 81.9903 - val_mse: 65.9631\n",
      "Epoch 15/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 97.7706 - mse: 81.9581 - val_loss: 92.5044 - val_mse: 76.8681\n",
      "Epoch 16/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 95.9737 - mse: 80.5471 - val_loss: 79.5590 - val_mse: 64.3258\n",
      "Epoch 17/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 101.8161 - mse: 86.7705 - val_loss: 88.7143 - val_mse: 73.8472\n",
      "Epoch 18/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 96.5903 - mse: 81.8851 - val_loss: 91.1287 - val_mse: 76.5680\n",
      "Epoch 19/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 98.1265 - mse: 83.7413 - val_loss: 73.1221 - val_mse: 58.9027\n",
      "Epoch 20/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 91.5526 - mse: 77.4927 - val_loss: 84.9002 - val_mse: 70.9677\n",
      "Epoch 21/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 91.7586 - mse: 77.9895 - val_loss: 80.4688 - val_mse: 66.8597\n",
      "Epoch 22/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 86.3680 - mse: 72.8987 - val_loss: 80.4052 - val_mse: 67.0935\n",
      "Epoch 23/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 86.6555 - mse: 73.4777 - val_loss: 79.9167 - val_mse: 66.8788\n",
      "Epoch 24/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 87.2982 - mse: 74.3773 - val_loss: 122.8091 - val_mse: 110.0472\n",
      "Epoch 25/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 87.9029 - mse: 75.2271 - val_loss: 70.3066 - val_mse: 57.7372\n",
      "Epoch 26/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 82.3935 - mse: 69.9501 - val_loss: 82.0300 - val_mse: 69.7197\n",
      "Epoch 27/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 85.2989 - mse: 73.0882 - val_loss: 76.2291 - val_mse: 64.0993\n",
      "Epoch 28/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 80.6843 - mse: 68.6653 - val_loss: 68.4540 - val_mse: 56.5385\n",
      "Epoch 29/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 80.5617 - mse: 68.7522 - val_loss: 70.4848 - val_mse: 58.7802\n",
      "Epoch 30/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 79.6508 - mse: 68.0637 - val_loss: 72.1479 - val_mse: 60.6387\n",
      "Epoch 31/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 79.0539 - mse: 67.6365 - val_loss: 79.4005 - val_mse: 68.1031\n",
      "Epoch 32/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 79.8856 - mse: 68.6596 - val_loss: 70.8797 - val_mse: 59.7233\n",
      "Epoch 33/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 76.4427 - mse: 65.3791 - val_loss: 74.6914 - val_mse: 63.7012\n",
      "Epoch 34/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 77.8869 - mse: 66.9887 - val_loss: 68.9998 - val_mse: 58.2038\n",
      "Epoch 35/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 75.4506 - mse: 64.7298 - val_loss: 68.7152 - val_mse: 58.0589\n",
      "Epoch 36/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 77.2215 - mse: 66.6372 - val_loss: 73.3648 - val_mse: 62.8306\n",
      "Epoch 37/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 75.0782 - mse: 64.6313 - val_loss: 63.2388 - val_mse: 52.8497\n",
      "Epoch 38/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 76.9380 - mse: 66.6307 - val_loss: 69.2976 - val_mse: 59.0435\n",
      "Epoch 39/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 75.4697 - mse: 65.3167 - val_loss: 65.8258 - val_mse: 55.7136\n",
      "Epoch 40/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 78.2712 - mse: 68.2411 - val_loss: 66.1731 - val_mse: 56.1850\n",
      "Epoch 41/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 73.7359 - mse: 63.8081 - val_loss: 68.2606 - val_mse: 58.4165\n",
      "Epoch 42/500\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 72.8783 - mse: 63.0812 - val_loss: 70.6851 - val_mse: 60.9542\n",
      "Epoch 43/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 75.3507 - mse: 65.6704 - val_loss: 91.6421 - val_mse: 82.0576\n",
      "Epoch 44/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 72.3789 - mse: 62.8372 - val_loss: 61.8837 - val_mse: 52.3960\n",
      "Epoch 45/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 71.0858 - mse: 61.6455 - val_loss: 61.2223 - val_mse: 51.8146\n",
      "Epoch 46/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 69.9255 - mse: 60.5612 - val_loss: 59.0956 - val_mse: 49.7662\n",
      "Epoch 47/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 69.6625 - mse: 60.3885 - val_loss: 103.3924 - val_mse: 94.2094\n",
      "Epoch 48/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 69.8339 - mse: 60.6711 - val_loss: 66.7436 - val_mse: 57.6083\n",
      "Epoch 49/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 70.1257 - mse: 61.0605 - val_loss: 67.4449 - val_mse: 58.4186\n",
      "Epoch 50/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 69.3451 - mse: 60.3595 - val_loss: 99.4443 - val_mse: 90.4820\n",
      "Epoch 51/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 70.8807 - mse: 61.9681 - val_loss: 59.4064 - val_mse: 50.5275\n",
      "Epoch 52/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 66.1742 - mse: 57.3376 - val_loss: 63.2810 - val_mse: 54.4787\n",
      "Epoch 53/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 69.4981 - mse: 60.7288 - val_loss: 57.1853 - val_mse: 48.4614\n",
      "Epoch 54/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 66.8622 - mse: 58.1739 - val_loss: 70.4472 - val_mse: 61.7830\n",
      "Epoch 55/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 66.3410 - mse: 57.7197 - val_loss: 72.1576 - val_mse: 63.5460\n",
      "Epoch 56/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 65.7740 - mse: 57.2152 - val_loss: 65.8698 - val_mse: 57.3409\n",
      "Epoch 57/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 67.6368 - mse: 59.1591 - val_loss: 61.3326 - val_mse: 52.8721\n",
      "Epoch 58/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 67.0365 - mse: 58.6259 - val_loss: 57.0581 - val_mse: 48.6675\n",
      "Epoch 59/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 66.5702 - mse: 58.2165 - val_loss: 74.8872 - val_mse: 66.5784\n",
      "Epoch 60/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 64.9566 - mse: 56.6597 - val_loss: 60.7515 - val_mse: 52.4981\n",
      "Epoch 61/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 64.7450 - mse: 56.5159 - val_loss: 66.1826 - val_mse: 57.9618\n",
      "Epoch 62/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 63.6976 - mse: 55.5149 - val_loss: 58.8202 - val_mse: 50.6656\n",
      "Epoch 63/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 65.7574 - mse: 57.6199 - val_loss: 60.4191 - val_mse: 52.3010\n",
      "Epoch 64/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 65.8175 - mse: 57.7252 - val_loss: 56.4661 - val_mse: 48.3992\n",
      "Epoch 65/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 65.3685 - mse: 57.3282 - val_loss: 70.4760 - val_mse: 62.4805\n",
      "Epoch 66/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 64.0445 - mse: 56.0535 - val_loss: 66.5620 - val_mse: 58.6022\n",
      "Epoch 67/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 62.0892 - mse: 54.1524 - val_loss: 59.6269 - val_mse: 51.7272\n",
      "Epoch 68/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 63.7241 - mse: 55.8481 - val_loss: 57.5985 - val_mse: 49.7179\n",
      "Epoch 69/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 65.7821 - mse: 57.9412 - val_loss: 65.1490 - val_mse: 57.3434\n",
      "Epoch 70/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 60.4945 - mse: 52.7002 - val_loss: 59.6786 - val_mse: 51.8921\n",
      "Epoch 71/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 62.1948 - mse: 54.4709 - val_loss: 61.6493 - val_mse: 53.9574\n",
      "Epoch 72/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 63.1680 - mse: 55.4864 - val_loss: 65.4524 - val_mse: 57.7725\n",
      "Epoch 73/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 62.1699 - mse: 54.5248 - val_loss: 52.9535 - val_mse: 45.3296\n",
      "Epoch 74/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 61.0965 - mse: 53.4855 - val_loss: 55.1869 - val_mse: 47.5876\n",
      "Epoch 75/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 61.3648 - mse: 53.7886 - val_loss: 54.8228 - val_mse: 47.2780\n",
      "Epoch 76/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 60.5268 - mse: 53.0089 - val_loss: 58.8328 - val_mse: 51.3360\n",
      "Epoch 77/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 61.5510 - mse: 54.0758 - val_loss: 65.7321 - val_mse: 58.2879\n",
      "Epoch 78/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 62.6378 - mse: 55.2084 - val_loss: 56.6817 - val_mse: 49.2610\n",
      "Epoch 79/500\n",
      "354/354 [==============================] - 2s 5ms/step - loss: 60.5551 - mse: 53.1607 - val_loss: 55.7331 - val_mse: 48.3691\n",
      "Epoch 80/500\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 60.4842 - mse: 53.1226 - val_loss: 54.0195 - val_mse: 46.6689\n",
      "Epoch 81/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 59.9949 - mse: 52.6669 - val_loss: 54.6175 - val_mse: 47.3111\n",
      "Epoch 82/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 58.1259 - mse: 50.8228 - val_loss: 55.2415 - val_mse: 47.9405\n",
      "Epoch 83/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 58.7129 - mse: 51.4325 - val_loss: 64.3420 - val_mse: 57.0428\n",
      "Epoch 84/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 59.2775 - mse: 52.0349 - val_loss: 49.2558 - val_mse: 42.0169\n",
      "Epoch 85/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 57.9530 - mse: 50.7326 - val_loss: 54.9154 - val_mse: 47.6997\n",
      "Epoch 86/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 58.2503 - mse: 51.0596 - val_loss: 52.2348 - val_mse: 45.0524\n",
      "Epoch 87/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 58.0763 - mse: 50.9052 - val_loss: 59.6217 - val_mse: 52.4602\n",
      "Epoch 88/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 59.1567 - mse: 52.0106 - val_loss: 56.4921 - val_mse: 49.3680\n",
      "Epoch 89/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 58.5959 - mse: 51.4821 - val_loss: 51.8884 - val_mse: 44.7992\n",
      "Epoch 90/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 57.4854 - mse: 50.4169 - val_loss: 57.2193 - val_mse: 50.1750\n",
      "Epoch 91/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 58.2411 - mse: 51.1876 - val_loss: 50.4739 - val_mse: 43.4260\n",
      "Epoch 92/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 56.8352 - mse: 49.8004 - val_loss: 52.4110 - val_mse: 45.3792\n",
      "Epoch 93/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 58.0199 - mse: 50.9888 - val_loss: 53.6353 - val_mse: 46.6119\n",
      "Epoch 94/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 57.1722 - mse: 50.1693 - val_loss: 53.4059 - val_mse: 46.4160\n",
      "Epoch 95/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 56.3349 - mse: 49.3604 - val_loss: 53.8901 - val_mse: 46.9445\n",
      "Epoch 96/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 57.8344 - mse: 50.8847 - val_loss: 55.8046 - val_mse: 48.8741\n",
      "Epoch 97/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 55.8128 - mse: 48.9109 - val_loss: 55.0763 - val_mse: 48.2071\n",
      "Epoch 98/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 55.3726 - mse: 48.4861 - val_loss: 52.0305 - val_mse: 45.1504\n",
      "Epoch 99/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 56.0731 - mse: 49.2068 - val_loss: 54.8011 - val_mse: 47.9579\n",
      "Epoch 100/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 55.6876 - mse: 48.8379 - val_loss: 53.1050 - val_mse: 46.2803\n",
      "Epoch 101/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 56.5423 - mse: 49.7384 - val_loss: 55.9744 - val_mse: 49.2056\n",
      "Epoch 102/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 57.2438 - mse: 50.4598 - val_loss: 50.2508 - val_mse: 43.4633\n",
      "Epoch 103/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.7945 - mse: 48.0149 - val_loss: 48.1765 - val_mse: 41.4102\n",
      "Epoch 104/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.8776 - mse: 48.1207 - val_loss: 51.2838 - val_mse: 44.5273\n",
      "Epoch 105/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 55.7186 - mse: 48.9646 - val_loss: 56.8223 - val_mse: 50.0723\n",
      "Epoch 106/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.1532 - mse: 47.4231 - val_loss: 50.9629 - val_mse: 44.2446\n",
      "Epoch 107/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.4903 - mse: 47.7779 - val_loss: 51.4161 - val_mse: 44.7399\n",
      "Epoch 108/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.3896 - mse: 47.7006 - val_loss: 52.8294 - val_mse: 46.1506\n",
      "Epoch 109/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.7637 - mse: 48.0898 - val_loss: 51.9198 - val_mse: 45.2414\n",
      "Epoch 110/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 53.9152 - mse: 47.2430 - val_loss: 56.9917 - val_mse: 50.3382\n",
      "Epoch 111/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 53.1690 - mse: 46.5105 - val_loss: 52.9833 - val_mse: 46.3271\n",
      "Epoch 112/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.6946 - mse: 48.0505 - val_loss: 54.4954 - val_mse: 47.8466\n",
      "Epoch 113/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 53.0900 - mse: 46.4485 - val_loss: 50.6705 - val_mse: 44.0439\n",
      "Epoch 114/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.6873 - mse: 46.0599 - val_loss: 56.0738 - val_mse: 49.4608\n",
      "Epoch 115/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 53.1437 - mse: 46.5375 - val_loss: 57.7109 - val_mse: 51.1077\n",
      "Epoch 116/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 53.8257 - mse: 47.2276 - val_loss: 48.9544 - val_mse: 42.3753\n",
      "Epoch 117/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.9375 - mse: 46.3749 - val_loss: 58.1235 - val_mse: 51.5804\n",
      "Epoch 118/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.7757 - mse: 46.2111 - val_loss: 48.5019 - val_mse: 41.9436\n",
      "Epoch 119/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.9839 - mse: 46.4276 - val_loss: 62.9424 - val_mse: 56.3667\n",
      "Epoch 120/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 54.2327 - mse: 47.7102 - val_loss: 50.4312 - val_mse: 43.9230\n",
      "Epoch 121/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.2672 - mse: 45.7479 - val_loss: 55.9698 - val_mse: 49.4339\n",
      "Epoch 122/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.8022 - mse: 46.2777 - val_loss: 50.6765 - val_mse: 44.1699\n",
      "Epoch 123/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.6577 - mse: 46.1350 - val_loss: 53.8168 - val_mse: 47.2921\n",
      "Epoch 124/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 51.2188 - mse: 44.6957 - val_loss: 48.5929 - val_mse: 42.0709\n",
      "Epoch 125/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 52.0708 - mse: 45.5583 - val_loss: 47.6983 - val_mse: 41.1908\n",
      "Epoch 126/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 51.1400 - mse: 44.6418 - val_loss: 52.1175 - val_mse: 45.5989\n",
      "Epoch 127/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.5420 - mse: 46.0507 - val_loss: 59.9325 - val_mse: 53.4807\n",
      "Epoch 128/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.1114 - mse: 45.6387 - val_loss: 49.4361 - val_mse: 42.9552\n",
      "Epoch 129/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.4423 - mse: 43.9625 - val_loss: 49.3468 - val_mse: 42.8781\n",
      "Epoch 130/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 51.4942 - mse: 45.0546 - val_loss: 48.1280 - val_mse: 41.6976\n",
      "Epoch 131/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 51.1775 - mse: 44.7374 - val_loss: 49.0212 - val_mse: 42.5880\n",
      "Epoch 132/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.7818 - mse: 44.3516 - val_loss: 66.8201 - val_mse: 60.3734\n",
      "Epoch 133/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 52.2910 - mse: 45.8707 - val_loss: 45.4422 - val_mse: 39.0254\n",
      "Epoch 134/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.6539 - mse: 44.2374 - val_loss: 51.2260 - val_mse: 44.8254\n",
      "Epoch 135/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.2222 - mse: 43.8091 - val_loss: 45.9636 - val_mse: 39.5710\n",
      "Epoch 136/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 51.3529 - mse: 44.9545 - val_loss: 51.3579 - val_mse: 44.9464\n",
      "Epoch 137/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 51.4792 - mse: 45.0671 - val_loss: 47.3508 - val_mse: 40.9375\n",
      "Epoch 138/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.0667 - mse: 43.6550 - val_loss: 49.0693 - val_mse: 42.6451\n",
      "Epoch 139/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.8089 - mse: 44.4097 - val_loss: 46.2301 - val_mse: 39.8588\n",
      "Epoch 140/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.1351 - mse: 43.7525 - val_loss: 46.1377 - val_mse: 39.7738\n",
      "Epoch 141/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.5212 - mse: 44.1401 - val_loss: 75.6309 - val_mse: 69.2962\n",
      "Epoch 142/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.7643 - mse: 44.3883 - val_loss: 48.7392 - val_mse: 42.3720\n",
      "Epoch 143/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.9906 - mse: 42.6212 - val_loss: 47.0413 - val_mse: 40.6666\n",
      "Epoch 144/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 51.4437 - mse: 45.0677 - val_loss: 46.3925 - val_mse: 40.0208\n",
      "Epoch 145/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.9053 - mse: 42.5398 - val_loss: 45.4371 - val_mse: 39.0742\n",
      "Epoch 146/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.2258 - mse: 41.8588 - val_loss: 50.9253 - val_mse: 44.5791\n",
      "Epoch 147/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 49.7240 - mse: 43.3710 - val_loss: 52.2249 - val_mse: 45.8681\n",
      "Epoch 148/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 50.5829 - mse: 44.2255 - val_loss: 47.9293 - val_mse: 41.5557\n",
      "Epoch 149/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.7089 - mse: 42.3538 - val_loss: 49.2800 - val_mse: 42.9199\n",
      "Epoch 150/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 50.7119 - mse: 44.3675 - val_loss: 46.9723 - val_mse: 40.6171\n",
      "Epoch 151/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 49.7501 - mse: 43.4123 - val_loss: 51.3487 - val_mse: 44.9943\n",
      "Epoch 152/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 51.7571 - mse: 45.4173 - val_loss: 47.9811 - val_mse: 41.6489\n",
      "Epoch 153/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.8218 - mse: 42.4859 - val_loss: 46.8787 - val_mse: 40.5558\n",
      "Epoch 154/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.5654 - mse: 42.2384 - val_loss: 47.1477 - val_mse: 40.8354\n",
      "Epoch 155/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.9547 - mse: 42.6335 - val_loss: 49.3607 - val_mse: 43.0364\n",
      "Epoch 156/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 49.7578 - mse: 43.4202 - val_loss: 48.4861 - val_mse: 42.1316\n",
      "Epoch 157/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.7044 - mse: 42.3582 - val_loss: 47.0321 - val_mse: 40.6962\n",
      "Epoch 158/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 48.5205 - mse: 42.1711 - val_loss: 47.5387 - val_mse: 41.1883\n",
      "Epoch 159/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.3665 - mse: 42.0269 - val_loss: 53.4418 - val_mse: 47.0883\n",
      "Epoch 160/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.3493 - mse: 42.0213 - val_loss: 45.0327 - val_mse: 38.7274\n",
      "Epoch 161/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.1984 - mse: 41.8755 - val_loss: 45.2985 - val_mse: 38.9786\n",
      "Epoch 162/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.3539 - mse: 41.0243 - val_loss: 43.6014 - val_mse: 37.2662\n",
      "Epoch 163/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.7029 - mse: 41.3615 - val_loss: 48.7825 - val_mse: 42.4668\n",
      "Epoch 164/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 49.4012 - mse: 43.0828 - val_loss: 49.5393 - val_mse: 43.2236\n",
      "Epoch 165/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 49.2788 - mse: 42.9535 - val_loss: 49.7432 - val_mse: 43.4086\n",
      "Epoch 166/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.6845 - mse: 41.3402 - val_loss: 44.8582 - val_mse: 38.5338\n",
      "Epoch 167/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 48.9666 - mse: 42.6512 - val_loss: 44.5938 - val_mse: 38.2900\n",
      "Epoch 168/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.9395 - mse: 41.6256 - val_loss: 44.0253 - val_mse: 37.6921\n",
      "Epoch 169/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.1500 - mse: 40.8296 - val_loss: 44.4582 - val_mse: 38.1473\n",
      "Epoch 170/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 46.5890 - mse: 40.2515 - val_loss: 44.3857 - val_mse: 38.0433\n",
      "Epoch 171/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 46.8520 - mse: 40.5136 - val_loss: 43.1392 - val_mse: 36.8176\n",
      "Epoch 172/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 46.9230 - mse: 40.5921 - val_loss: 47.5867 - val_mse: 41.2620\n",
      "Epoch 173/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 46.6367 - mse: 40.3236 - val_loss: 48.2227 - val_mse: 41.9049\n",
      "Epoch 174/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.0585 - mse: 40.7401 - val_loss: 47.4196 - val_mse: 41.1156\n",
      "Epoch 175/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.0443 - mse: 40.7354 - val_loss: 45.4944 - val_mse: 39.1921\n",
      "Epoch 176/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.4096 - mse: 41.0949 - val_loss: 46.7341 - val_mse: 40.4000\n",
      "Epoch 177/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 47.1956 - mse: 40.8631 - val_loss: 47.9990 - val_mse: 41.6824\n",
      "Epoch 178/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.4018 - mse: 41.0914 - val_loss: 48.6514 - val_mse: 42.3243\n",
      "Epoch 179/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 46.8470 - mse: 40.5233 - val_loss: 45.7597 - val_mse: 39.4394\n",
      "Epoch 180/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 46.6477 - mse: 40.3315 - val_loss: 50.9203 - val_mse: 44.5958\n",
      "Epoch 181/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.8433 - mse: 39.5297 - val_loss: 44.0392 - val_mse: 37.7037\n",
      "Epoch 182/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 46.3995 - mse: 40.0664 - val_loss: 46.8431 - val_mse: 40.5083\n",
      "Epoch 183/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 47.1220 - mse: 40.7838 - val_loss: 42.4031 - val_mse: 36.0433\n",
      "Epoch 184/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.7416 - mse: 39.3909 - val_loss: 46.0675 - val_mse: 39.7219\n",
      "Epoch 185/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.4232 - mse: 39.0829 - val_loss: 45.3541 - val_mse: 39.0203\n",
      "Epoch 186/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.9442 - mse: 39.5946 - val_loss: 44.5451 - val_mse: 38.2076\n",
      "Epoch 187/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 46.8842 - mse: 40.5438 - val_loss: 48.0732 - val_mse: 41.7264\n",
      "Epoch 188/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 46.2120 - mse: 39.8764 - val_loss: 43.3413 - val_mse: 37.0184\n",
      "Epoch 189/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 44.9794 - mse: 38.6490 - val_loss: 42.3919 - val_mse: 36.0450\n",
      "Epoch 190/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.8632 - mse: 38.5184 - val_loss: 42.3343 - val_mse: 35.9997\n",
      "Epoch 191/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.7334 - mse: 39.4029 - val_loss: 44.2000 - val_mse: 37.8943\n",
      "Epoch 192/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.5965 - mse: 39.2743 - val_loss: 47.1599 - val_mse: 40.8378\n",
      "Epoch 193/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 45.8921 - mse: 39.5817 - val_loss: 40.2730 - val_mse: 33.9575\n",
      "Epoch 194/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.6602 - mse: 38.3518 - val_loss: 43.6198 - val_mse: 37.3004\n",
      "Epoch 195/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 44.9901 - mse: 38.6694 - val_loss: 41.2732 - val_mse: 34.9537\n",
      "Epoch 196/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 45.0352 - mse: 38.7148 - val_loss: 45.3891 - val_mse: 39.0827\n",
      "Epoch 197/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.5200 - mse: 39.2034 - val_loss: 45.5187 - val_mse: 39.2246\n",
      "Epoch 198/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.0500 - mse: 38.7236 - val_loss: 45.9540 - val_mse: 39.6235\n",
      "Epoch 199/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.7240 - mse: 38.3982 - val_loss: 43.9576 - val_mse: 37.6237\n",
      "Epoch 200/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 44.9465 - mse: 38.6181 - val_loss: 48.3490 - val_mse: 42.0263\n",
      "Epoch 201/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 43.3968 - mse: 37.0786 - val_loss: 44.3258 - val_mse: 37.9829\n",
      "Epoch 202/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 45.7967 - mse: 39.4704 - val_loss: 46.4347 - val_mse: 40.1089\n",
      "Epoch 203/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.0397 - mse: 37.7264 - val_loss: 46.1627 - val_mse: 39.8608\n",
      "Epoch 204/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.1581 - mse: 37.8295 - val_loss: 42.9982 - val_mse: 36.6820\n",
      "Epoch 205/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 44.2169 - mse: 37.8977 - val_loss: 42.0202 - val_mse: 35.7131\n",
      "Epoch 206/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 42.7952 - mse: 36.4760 - val_loss: 44.1671 - val_mse: 37.8296\n",
      "Epoch 207/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 43.7825 - mse: 37.4601 - val_loss: 41.5736 - val_mse: 35.2416\n",
      "Epoch 208/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.1169 - mse: 37.8094 - val_loss: 44.7242 - val_mse: 38.4348\n",
      "Epoch 209/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 43.4288 - mse: 37.1316 - val_loss: 41.7833 - val_mse: 35.4906\n",
      "Epoch 210/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.2604 - mse: 37.9593 - val_loss: 44.5424 - val_mse: 38.2192\n",
      "Epoch 211/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 43.7899 - mse: 37.4998 - val_loss: 43.0115 - val_mse: 36.7251\n",
      "Epoch 212/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 44.4091 - mse: 38.1133 - val_loss: 44.8205 - val_mse: 38.5230\n",
      "Epoch 213/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 42.8101 - mse: 36.5003 - val_loss: 40.6568 - val_mse: 34.3589\n",
      "Epoch 214/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 42.8015 - mse: 36.5009 - val_loss: 50.6595 - val_mse: 44.3819\n",
      "Epoch 215/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 43.5784 - mse: 37.2836 - val_loss: 45.4731 - val_mse: 39.1933\n",
      "Epoch 216/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.3026 - mse: 38.0262 - val_loss: 42.5798 - val_mse: 36.2998\n",
      "Epoch 217/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 44.4236 - mse: 38.1431 - val_loss: 42.5760 - val_mse: 36.2767\n",
      "Epoch 218/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 43.1153 - mse: 36.8305 - val_loss: 40.5817 - val_mse: 34.2924\n",
      "Epoch 219/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 43.5820 - mse: 37.3165 - val_loss: 49.3567 - val_mse: 43.1032\n",
      "Epoch 220/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.3535 - mse: 36.0801 - val_loss: 43.6785 - val_mse: 37.4101\n",
      "Epoch 221/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.9155 - mse: 36.6324 - val_loss: 40.5502 - val_mse: 34.2394\n",
      "Epoch 222/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.8609 - mse: 36.5776 - val_loss: 42.5482 - val_mse: 36.2711\n",
      "Epoch 223/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 43.4829 - mse: 37.1845 - val_loss: 44.0035 - val_mse: 37.7088\n",
      "Epoch 224/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.7436 - mse: 36.4552 - val_loss: 44.0636 - val_mse: 37.7628\n",
      "Epoch 225/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.7797 - mse: 36.4829 - val_loss: 50.7761 - val_mse: 44.4996\n",
      "Epoch 226/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.4907 - mse: 36.1951 - val_loss: 41.0071 - val_mse: 34.7068\n",
      "Epoch 227/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.6532 - mse: 36.3468 - val_loss: 42.6978 - val_mse: 36.3882\n",
      "Epoch 228/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 43.3982 - mse: 37.0901 - val_loss: 43.7493 - val_mse: 37.4427\n",
      "Epoch 229/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.8639 - mse: 36.5585 - val_loss: 42.3178 - val_mse: 36.0134\n",
      "Epoch 230/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 42.5884 - mse: 36.2921 - val_loss: 43.8885 - val_mse: 37.6009\n",
      "Epoch 231/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.1436 - mse: 34.8525 - val_loss: 43.2327 - val_mse: 36.9323\n",
      "Epoch 232/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.5713 - mse: 35.2689 - val_loss: 42.6311 - val_mse: 36.3065\n",
      "Epoch 233/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.5966 - mse: 36.2950 - val_loss: 44.2783 - val_mse: 37.9722\n",
      "Epoch 234/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.7309 - mse: 35.4348 - val_loss: 45.9337 - val_mse: 39.6576\n",
      "Epoch 235/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.2583 - mse: 34.9661 - val_loss: 42.8248 - val_mse: 36.5292\n",
      "Epoch 236/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 42.0366 - mse: 35.7477 - val_loss: 50.4912 - val_mse: 44.1841\n",
      "Epoch 237/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.5140 - mse: 35.2328 - val_loss: 39.5014 - val_mse: 33.2291\n",
      "Epoch 238/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.8432 - mse: 35.5664 - val_loss: 49.5831 - val_mse: 43.2692\n",
      "Epoch 239/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.1064 - mse: 35.8146 - val_loss: 41.9368 - val_mse: 35.6326\n",
      "Epoch 240/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.0308 - mse: 34.7232 - val_loss: 46.3653 - val_mse: 40.0511\n",
      "Epoch 241/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.1841 - mse: 35.8750 - val_loss: 41.9049 - val_mse: 35.6066\n",
      "Epoch 242/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 42.4774 - mse: 36.1722 - val_loss: 39.2841 - val_mse: 32.9879\n",
      "Epoch 243/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.5845 - mse: 34.2895 - val_loss: 41.7521 - val_mse: 35.4758\n",
      "Epoch 244/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 43.6018 - mse: 37.3190 - val_loss: 39.0657 - val_mse: 32.7755\n",
      "Epoch 245/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 42.2950 - mse: 36.0067 - val_loss: 41.8262 - val_mse: 35.5284\n",
      "Epoch 246/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.2416 - mse: 34.9412 - val_loss: 40.1271 - val_mse: 33.8225\n",
      "Epoch 247/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 39.9876 - mse: 33.6809 - val_loss: 46.0077 - val_mse: 39.7306\n",
      "Epoch 248/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.4853 - mse: 35.1877 - val_loss: 40.7454 - val_mse: 34.4582\n",
      "Epoch 249/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.0640 - mse: 34.7718 - val_loss: 42.5020 - val_mse: 36.2246\n",
      "Epoch 250/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 40.1805 - mse: 33.9021 - val_loss: 44.9587 - val_mse: 38.6905\n",
      "Epoch 251/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.6741 - mse: 34.3940 - val_loss: 39.8158 - val_mse: 33.5189\n",
      "Epoch 252/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.2104 - mse: 34.9227 - val_loss: 42.7947 - val_mse: 36.5326\n",
      "Epoch 253/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 40.4691 - mse: 34.1902 - val_loss: 40.3199 - val_mse: 34.0433\n",
      "Epoch 254/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.1228 - mse: 34.8348 - val_loss: 40.5100 - val_mse: 34.2318\n",
      "Epoch 255/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.5481 - mse: 34.2679 - val_loss: 40.8288 - val_mse: 34.5532\n",
      "Epoch 256/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.8905 - mse: 33.6070 - val_loss: 38.4413 - val_mse: 32.1528\n",
      "Epoch 257/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.2937 - mse: 34.0008 - val_loss: 38.8211 - val_mse: 32.5329\n",
      "Epoch 258/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.8286 - mse: 33.5266 - val_loss: 40.0584 - val_mse: 33.7754\n",
      "Epoch 259/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.0648 - mse: 34.7716 - val_loss: 45.6051 - val_mse: 39.3178\n",
      "Epoch 260/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.8491 - mse: 34.5502 - val_loss: 41.4444 - val_mse: 35.1513\n",
      "Epoch 261/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.9732 - mse: 34.6954 - val_loss: 48.7344 - val_mse: 42.4760\n",
      "Epoch 262/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.0148 - mse: 35.7295 - val_loss: 44.1540 - val_mse: 37.8489\n",
      "Epoch 263/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.6713 - mse: 36.3922 - val_loss: 41.9321 - val_mse: 35.6587\n",
      "Epoch 264/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.8888 - mse: 35.6057 - val_loss: 43.2273 - val_mse: 36.9447\n",
      "Epoch 265/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.6523 - mse: 35.3743 - val_loss: 39.3048 - val_mse: 33.0203\n",
      "Epoch 266/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.8968 - mse: 35.5891 - val_loss: 41.2054 - val_mse: 34.8945\n",
      "Epoch 267/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 42.0841 - mse: 35.7749 - val_loss: 42.6838 - val_mse: 36.3920\n",
      "Epoch 268/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 41.2131 - mse: 34.9047 - val_loss: 48.4664 - val_mse: 42.1348\n",
      "Epoch 269/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 40.1955 - mse: 33.8787 - val_loss: 41.9654 - val_mse: 35.6542\n",
      "Epoch 270/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.6153 - mse: 34.3132 - val_loss: 38.9765 - val_mse: 32.6743\n",
      "Epoch 271/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.6508 - mse: 35.3463 - val_loss: 39.7366 - val_mse: 33.4068\n",
      "Epoch 272/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.0896 - mse: 34.7729 - val_loss: 39.4481 - val_mse: 33.1362\n",
      "Epoch 273/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.4817 - mse: 34.1870 - val_loss: 40.0336 - val_mse: 33.7474\n",
      "Epoch 274/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.3170 - mse: 35.0271 - val_loss: 43.9373 - val_mse: 37.6378\n",
      "Epoch 275/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.8057 - mse: 34.4982 - val_loss: 40.3247 - val_mse: 34.0333\n",
      "Epoch 276/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.0101 - mse: 34.7148 - val_loss: 39.5680 - val_mse: 33.2704\n",
      "Epoch 277/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.9999 - mse: 34.6955 - val_loss: 43.0154 - val_mse: 36.7327\n",
      "Epoch 278/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.6918 - mse: 34.3847 - val_loss: 41.7412 - val_mse: 35.4205\n",
      "Epoch 279/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.3085 - mse: 33.9959 - val_loss: 41.4397 - val_mse: 35.1225\n",
      "Epoch 280/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.5054 - mse: 35.2057 - val_loss: 43.8865 - val_mse: 37.5788\n",
      "Epoch 281/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.8806 - mse: 34.5789 - val_loss: 38.7598 - val_mse: 32.4631\n",
      "Epoch 282/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.4664 - mse: 33.1636 - val_loss: 45.6105 - val_mse: 39.3328\n",
      "Epoch 283/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.4454 - mse: 35.1417 - val_loss: 41.4555 - val_mse: 35.1473\n",
      "Epoch 284/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.7872 - mse: 34.4733 - val_loss: 44.3522 - val_mse: 38.0295\n",
      "Epoch 285/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.4887 - mse: 34.1834 - val_loss: 37.7049 - val_mse: 31.4005\n",
      "Epoch 286/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.2751 - mse: 33.9711 - val_loss: 40.2176 - val_mse: 33.9122\n",
      "Epoch 287/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.0079 - mse: 34.6921 - val_loss: 39.7397 - val_mse: 33.4133\n",
      "Epoch 288/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.7808 - mse: 33.4744 - val_loss: 39.3698 - val_mse: 33.0652\n",
      "Epoch 289/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.5493 - mse: 33.2338 - val_loss: 39.2514 - val_mse: 32.9404\n",
      "Epoch 290/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.3146 - mse: 33.9993 - val_loss: 40.6280 - val_mse: 34.3173\n",
      "Epoch 291/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.4456 - mse: 34.1297 - val_loss: 40.8323 - val_mse: 34.5138\n",
      "Epoch 292/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.9533 - mse: 33.6446 - val_loss: 39.7798 - val_mse: 33.4585\n",
      "Epoch 293/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.2065 - mse: 34.8988 - val_loss: 43.0990 - val_mse: 36.7811\n",
      "Epoch 294/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.3582 - mse: 33.0511 - val_loss: 41.6337 - val_mse: 35.3599\n",
      "Epoch 295/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.8818 - mse: 34.5798 - val_loss: 40.9795 - val_mse: 34.6552\n",
      "Epoch 296/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.0794 - mse: 33.7762 - val_loss: 40.8180 - val_mse: 34.5006\n",
      "Epoch 297/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.7184 - mse: 34.4175 - val_loss: 39.7578 - val_mse: 33.4431\n",
      "Epoch 298/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.5309 - mse: 34.2250 - val_loss: 42.4362 - val_mse: 36.1411\n",
      "Epoch 299/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.6629 - mse: 33.3648 - val_loss: 38.2199 - val_mse: 31.9323\n",
      "Epoch 300/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.0543 - mse: 33.7574 - val_loss: 43.0305 - val_mse: 36.7393\n",
      "Epoch 301/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.7761 - mse: 33.4693 - val_loss: 41.0254 - val_mse: 34.7289\n",
      "Epoch 302/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.4478 - mse: 33.1573 - val_loss: 39.2233 - val_mse: 32.9506\n",
      "Epoch 303/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 41.4538 - mse: 35.1583 - val_loss: 40.8318 - val_mse: 34.5202\n",
      "Epoch 304/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.6810 - mse: 34.3794 - val_loss: 41.4157 - val_mse: 35.1176\n",
      "Epoch 305/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.7180 - mse: 33.4066 - val_loss: 40.6957 - val_mse: 34.3776\n",
      "Epoch 306/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.1458 - mse: 32.8349 - val_loss: 40.2988 - val_mse: 34.0090\n",
      "Epoch 307/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.5341 - mse: 34.2244 - val_loss: 41.7597 - val_mse: 35.4569\n",
      "Epoch 308/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.1181 - mse: 33.8052 - val_loss: 40.2428 - val_mse: 33.9159\n",
      "Epoch 309/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.4042 - mse: 33.0933 - val_loss: 42.6304 - val_mse: 36.3180\n",
      "Epoch 310/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.6705 - mse: 33.3613 - val_loss: 43.0354 - val_mse: 36.7385\n",
      "Epoch 311/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.4726 - mse: 33.1582 - val_loss: 40.0763 - val_mse: 33.7709\n",
      "Epoch 312/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.2033 - mse: 33.8981 - val_loss: 41.8094 - val_mse: 35.5171\n",
      "Epoch 313/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.1120 - mse: 32.8093 - val_loss: 42.9517 - val_mse: 36.6264\n",
      "Epoch 314/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.6217 - mse: 33.3182 - val_loss: 40.8481 - val_mse: 34.5430\n",
      "Epoch 315/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.7189 - mse: 33.4155 - val_loss: 41.6936 - val_mse: 35.4000\n",
      "Epoch 316/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.5605 - mse: 33.2443 - val_loss: 43.7978 - val_mse: 37.4605\n",
      "Epoch 317/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.2840 - mse: 32.9747 - val_loss: 48.5655 - val_mse: 42.2926\n",
      "Epoch 318/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.6703 - mse: 32.3727 - val_loss: 38.6039 - val_mse: 32.3080\n",
      "Epoch 319/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.0542 - mse: 33.7581 - val_loss: 40.0718 - val_mse: 33.7837\n",
      "Epoch 320/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.9795 - mse: 32.6939 - val_loss: 39.0218 - val_mse: 32.7436\n",
      "Epoch 321/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.7678 - mse: 32.4627 - val_loss: 38.8601 - val_mse: 32.5611\n",
      "Epoch 322/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.1102 - mse: 32.8019 - val_loss: 41.6569 - val_mse: 35.3611\n",
      "Epoch 323/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 40.0683 - mse: 33.7742 - val_loss: 38.2738 - val_mse: 31.9758\n",
      "Epoch 324/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.7798 - mse: 32.4759 - val_loss: 40.4644 - val_mse: 34.1586\n",
      "Epoch 325/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.6837 - mse: 32.3857 - val_loss: 45.1967 - val_mse: 38.8966\n",
      "Epoch 326/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.7910 - mse: 33.4932 - val_loss: 40.0504 - val_mse: 33.7818\n",
      "Epoch 327/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.6873 - mse: 32.4087 - val_loss: 39.1632 - val_mse: 32.8732\n",
      "Epoch 328/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.8627 - mse: 33.5853 - val_loss: 44.3541 - val_mse: 38.0590\n",
      "Epoch 329/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.4033 - mse: 33.1219 - val_loss: 40.3697 - val_mse: 34.0935\n",
      "Epoch 330/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.4560 - mse: 33.1719 - val_loss: 47.0612 - val_mse: 40.7925\n",
      "Epoch 331/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.6883 - mse: 31.4032 - val_loss: 39.3905 - val_mse: 33.1113\n",
      "Epoch 332/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.6624 - mse: 32.3666 - val_loss: 45.0491 - val_mse: 38.7561\n",
      "Epoch 333/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.2481 - mse: 31.9801 - val_loss: 38.8556 - val_mse: 32.5850\n",
      "Epoch 334/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.7757 - mse: 32.5078 - val_loss: 39.5496 - val_mse: 33.2831\n",
      "Epoch 335/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 39.1845 - mse: 32.9037 - val_loss: 42.2379 - val_mse: 35.9713\n",
      "Epoch 336/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.4261 - mse: 33.1533 - val_loss: 38.2678 - val_mse: 31.9974\n",
      "Epoch 337/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.9203 - mse: 32.6573 - val_loss: 39.1148 - val_mse: 32.8773\n",
      "Epoch 338/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.1828 - mse: 30.9253 - val_loss: 41.8438 - val_mse: 35.5830\n",
      "Epoch 339/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.5413 - mse: 31.3018 - val_loss: 38.9540 - val_mse: 32.7082\n",
      "Epoch 340/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.9835 - mse: 32.7413 - val_loss: 37.2390 - val_mse: 30.9965\n",
      "Epoch 341/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.4339 - mse: 31.1901 - val_loss: 37.7491 - val_mse: 31.4991\n",
      "Epoch 342/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.5247 - mse: 31.2696 - val_loss: 38.2169 - val_mse: 31.9697\n",
      "Epoch 343/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.2218 - mse: 30.9592 - val_loss: 41.0276 - val_mse: 34.7513\n",
      "Epoch 344/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.4171 - mse: 32.1646 - val_loss: 41.4817 - val_mse: 35.2051\n",
      "Epoch 345/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.3560 - mse: 31.0905 - val_loss: 39.6485 - val_mse: 33.3769\n",
      "Epoch 346/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.1970 - mse: 31.9477 - val_loss: 42.1412 - val_mse: 35.9119\n",
      "Epoch 347/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.6281 - mse: 33.3774 - val_loss: 41.1898 - val_mse: 34.9261\n",
      "Epoch 348/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 39.1527 - mse: 32.8870 - val_loss: 40.1070 - val_mse: 33.8299\n",
      "Epoch 349/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.7958 - mse: 32.5165 - val_loss: 37.2863 - val_mse: 31.0090\n",
      "Epoch 350/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.3305 - mse: 31.0726 - val_loss: 37.8550 - val_mse: 31.5853\n",
      "Epoch 351/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.9652 - mse: 31.7063 - val_loss: 38.5250 - val_mse: 32.2770\n",
      "Epoch 352/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.3125 - mse: 32.0641 - val_loss: 39.8051 - val_mse: 33.5527\n",
      "Epoch 353/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.3029 - mse: 31.0492 - val_loss: 38.1118 - val_mse: 31.8746\n",
      "Epoch 354/500\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 38.1881 - mse: 31.9493 - val_loss: 39.8117 - val_mse: 33.5966\n",
      "Epoch 355/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 38.2944 - mse: 32.0747 - val_loss: 40.7140 - val_mse: 34.4756\n",
      "Epoch 356/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.0195 - mse: 31.7828 - val_loss: 42.2879 - val_mse: 36.0625\n",
      "Epoch 357/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.6590 - mse: 31.4065 - val_loss: 37.9257 - val_mse: 31.6619\n",
      "Epoch 358/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.3631 - mse: 32.1098 - val_loss: 47.3617 - val_mse: 41.1300\n",
      "Epoch 359/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.6964 - mse: 32.4449 - val_loss: 38.1474 - val_mse: 31.8969\n",
      "Epoch 360/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 38.7616 - mse: 32.5187 - val_loss: 39.6345 - val_mse: 33.3916\n",
      "Epoch 361/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.7750 - mse: 32.5526 - val_loss: 42.6637 - val_mse: 36.4359\n",
      "Epoch 362/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 37.9260 - mse: 31.7003 - val_loss: 40.1711 - val_mse: 33.9643\n",
      "Epoch 363/500\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 38.2149 - mse: 31.9783 - val_loss: 39.3390 - val_mse: 33.0903\n",
      "Epoch 364/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 38.9444 - mse: 32.6952 - val_loss: 42.6885 - val_mse: 36.4561\n",
      "Epoch 365/500\n",
      "354/354 [==============================] - 1s 4ms/step - loss: 38.1016 - mse: 31.8498 - val_loss: 38.7767 - val_mse: 32.5236\n",
      "Epoch 366/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 38.0482 - mse: 31.7892 - val_loss: 37.1369 - val_mse: 30.8794\n",
      "Epoch 367/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.3135 - mse: 32.0670 - val_loss: 38.9634 - val_mse: 32.7188\n",
      "Epoch 368/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.1575 - mse: 31.9071 - val_loss: 38.6101 - val_mse: 32.3531\n",
      "Epoch 369/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.8306 - mse: 31.5903 - val_loss: 43.3596 - val_mse: 37.1505\n",
      "Epoch 370/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 37.9186 - mse: 31.6788 - val_loss: 39.1526 - val_mse: 32.9032\n",
      "Epoch 371/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.8258 - mse: 31.5878 - val_loss: 39.7313 - val_mse: 33.4798\n",
      "Epoch 372/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.6076 - mse: 32.3685 - val_loss: 38.7183 - val_mse: 32.4859\n",
      "Epoch 373/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.5870 - mse: 31.3628 - val_loss: 39.5519 - val_mse: 33.3290\n",
      "Epoch 374/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.6372 - mse: 31.4061 - val_loss: 39.4427 - val_mse: 33.2073\n",
      "Epoch 375/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.2096 - mse: 31.9668 - val_loss: 38.1104 - val_mse: 31.8758\n",
      "Epoch 376/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.6911 - mse: 31.4646 - val_loss: 38.1710 - val_mse: 31.9190\n",
      "Epoch 377/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.0934 - mse: 31.8530 - val_loss: 41.0844 - val_mse: 34.8646\n",
      "Epoch 378/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.3973 - mse: 32.1728 - val_loss: 39.1343 - val_mse: 32.9060\n",
      "Epoch 379/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.7414 - mse: 30.5171 - val_loss: 38.9505 - val_mse: 32.7229\n",
      "Epoch 380/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.2812 - mse: 32.0480 - val_loss: 39.0982 - val_mse: 32.8751\n",
      "Epoch 381/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.6186 - mse: 31.3962 - val_loss: 41.0485 - val_mse: 34.8039\n",
      "Epoch 382/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.7787 - mse: 31.5519 - val_loss: 41.1228 - val_mse: 34.9087\n",
      "Epoch 383/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.4836 - mse: 31.2614 - val_loss: 38.1802 - val_mse: 31.9464\n",
      "Epoch 384/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.7961 - mse: 31.5606 - val_loss: 41.1999 - val_mse: 34.9752\n",
      "Epoch 385/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.2535 - mse: 31.0139 - val_loss: 41.0350 - val_mse: 34.8004\n",
      "Epoch 386/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.8976 - mse: 31.6609 - val_loss: 36.8363 - val_mse: 30.5995\n",
      "Epoch 387/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.0630 - mse: 30.8363 - val_loss: 37.9150 - val_mse: 31.7215\n",
      "Epoch 388/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.4919 - mse: 31.2741 - val_loss: 37.2490 - val_mse: 31.0294\n",
      "Epoch 389/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 36.5955 - mse: 30.3511 - val_loss: 38.4453 - val_mse: 32.2024\n",
      "Epoch 390/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 36.5670 - mse: 30.3143 - val_loss: 43.9469 - val_mse: 37.7114\n",
      "Epoch 391/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.4861 - mse: 32.2293 - val_loss: 43.8892 - val_mse: 37.6600\n",
      "Epoch 392/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.4527 - mse: 30.2039 - val_loss: 37.0186 - val_mse: 30.7862\n",
      "Epoch 393/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 38.3196 - mse: 32.0942 - val_loss: 38.8903 - val_mse: 32.6592\n",
      "Epoch 394/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 36.7093 - mse: 30.4792 - val_loss: 39.1245 - val_mse: 32.8904\n",
      "Epoch 395/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.1325 - mse: 30.8948 - val_loss: 49.7358 - val_mse: 43.4888\n",
      "Epoch 396/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.7086 - mse: 30.4747 - val_loss: 36.8548 - val_mse: 30.6228\n",
      "Epoch 397/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.8521 - mse: 30.6168 - val_loss: 37.3853 - val_mse: 31.1619\n",
      "Epoch 398/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 37.3234 - mse: 31.0900 - val_loss: 37.3147 - val_mse: 31.0930\n",
      "Epoch 399/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.9832 - mse: 31.7587 - val_loss: 39.3814 - val_mse: 33.1491\n",
      "Epoch 400/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.9821 - mse: 29.7599 - val_loss: 38.5665 - val_mse: 32.3456\n",
      "Epoch 401/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.4840 - mse: 31.2625 - val_loss: 38.0586 - val_mse: 31.8260\n",
      "Epoch 402/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.6411 - mse: 30.4097 - val_loss: 37.2697 - val_mse: 31.0370\n",
      "Epoch 403/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.4009 - mse: 30.1798 - val_loss: 40.2786 - val_mse: 34.0678\n",
      "Epoch 404/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.3561 - mse: 30.1395 - val_loss: 48.5175 - val_mse: 42.3395\n",
      "Epoch 405/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.3086 - mse: 30.1041 - val_loss: 45.8463 - val_mse: 39.6169\n",
      "Epoch 406/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.6943 - mse: 30.4907 - val_loss: 35.3901 - val_mse: 29.1869\n",
      "Epoch 407/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.3303 - mse: 30.1364 - val_loss: 37.4181 - val_mse: 31.2483\n",
      "Epoch 408/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 36.7311 - mse: 30.5493 - val_loss: 38.6201 - val_mse: 32.4272\n",
      "Epoch 409/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.7935 - mse: 30.6024 - val_loss: 40.7456 - val_mse: 34.5366\n",
      "Epoch 410/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.1682 - mse: 30.9588 - val_loss: 41.5558 - val_mse: 35.3462\n",
      "Epoch 411/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.1590 - mse: 30.9407 - val_loss: 42.9270 - val_mse: 36.7035\n",
      "Epoch 412/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.8171 - mse: 30.6127 - val_loss: 36.5593 - val_mse: 30.3683\n",
      "Epoch 413/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.6413 - mse: 30.4395 - val_loss: 37.9748 - val_mse: 31.7880\n",
      "Epoch 414/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.3799 - mse: 29.1837 - val_loss: 38.5724 - val_mse: 32.3659\n",
      "Epoch 415/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.4622 - mse: 30.2645 - val_loss: 40.5988 - val_mse: 34.3946\n",
      "Epoch 416/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.3219 - mse: 30.1217 - val_loss: 36.5751 - val_mse: 30.3659\n",
      "Epoch 417/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.3404 - mse: 30.1138 - val_loss: 36.5870 - val_mse: 30.3606\n",
      "Epoch 418/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 35.6612 - mse: 29.4366 - val_loss: 36.7798 - val_mse: 30.5626\n",
      "Epoch 419/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.2455 - mse: 30.0329 - val_loss: 40.7195 - val_mse: 34.5090\n",
      "Epoch 420/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.3896 - mse: 30.1916 - val_loss: 42.3506 - val_mse: 36.1740\n",
      "Epoch 421/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.0396 - mse: 30.8436 - val_loss: 38.5151 - val_mse: 32.3194\n",
      "Epoch 422/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 35.9785 - mse: 29.7876 - val_loss: 36.8057 - val_mse: 30.6164\n",
      "Epoch 423/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.3493 - mse: 30.1564 - val_loss: 43.9630 - val_mse: 37.7972\n",
      "Epoch 424/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 37.2292 - mse: 31.0411 - val_loss: 38.2124 - val_mse: 32.0304\n",
      "Epoch 425/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.1103 - mse: 29.9182 - val_loss: 37.8716 - val_mse: 31.7006\n",
      "Epoch 426/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.9611 - mse: 29.7991 - val_loss: 38.7380 - val_mse: 32.5797\n",
      "Epoch 427/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.6598 - mse: 29.5035 - val_loss: 36.7845 - val_mse: 30.6186\n",
      "Epoch 428/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.0379 - mse: 28.8679 - val_loss: 35.7519 - val_mse: 29.5825\n",
      "Epoch 429/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 37.9994 - mse: 31.8382 - val_loss: 38.5145 - val_mse: 32.3652\n",
      "Epoch 430/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.1668 - mse: 29.0298 - val_loss: 36.8615 - val_mse: 30.7091\n",
      "Epoch 431/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.9861 - mse: 29.8327 - val_loss: 36.3358 - val_mse: 30.1926\n",
      "Epoch 432/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.0113 - mse: 28.8585 - val_loss: 38.1008 - val_mse: 31.9676\n",
      "Epoch 433/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8933 - mse: 28.7433 - val_loss: 36.6954 - val_mse: 30.5531\n",
      "Epoch 434/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.6131 - mse: 29.4772 - val_loss: 41.2672 - val_mse: 35.1259\n",
      "Epoch 435/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.0034 - mse: 28.8760 - val_loss: 39.8517 - val_mse: 33.7408\n",
      "Epoch 436/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.8085 - mse: 30.6837 - val_loss: 37.9161 - val_mse: 31.8053\n",
      "Epoch 437/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2407 - mse: 29.1122 - val_loss: 40.5087 - val_mse: 34.3622\n",
      "Epoch 438/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2407 - mse: 29.1161 - val_loss: 41.6617 - val_mse: 35.5294\n",
      "Epoch 439/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2650 - mse: 29.1456 - val_loss: 39.0214 - val_mse: 32.9077\n",
      "Epoch 440/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.3820 - mse: 29.2614 - val_loss: 37.9293 - val_mse: 31.8218\n",
      "Epoch 441/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 34.9048 - mse: 28.7918 - val_loss: 38.5765 - val_mse: 32.4950\n",
      "Epoch 442/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2293 - mse: 29.1233 - val_loss: 38.4840 - val_mse: 32.3888\n",
      "Epoch 443/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2174 - mse: 29.1090 - val_loss: 37.6089 - val_mse: 31.5007\n",
      "Epoch 444/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.0574 - mse: 29.9455 - val_loss: 38.0248 - val_mse: 31.9249\n",
      "Epoch 445/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.9242 - mse: 28.8143 - val_loss: 35.6894 - val_mse: 29.5861\n",
      "Epoch 446/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8632 - mse: 28.7726 - val_loss: 36.8820 - val_mse: 30.8020\n",
      "Epoch 447/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.2816 - mse: 28.2004 - val_loss: 37.5288 - val_mse: 31.4326\n",
      "Epoch 448/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.7089 - mse: 29.6085 - val_loss: 35.9875 - val_mse: 29.8806\n",
      "Epoch 449/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.7804 - mse: 28.6776 - val_loss: 34.7305 - val_mse: 28.6408\n",
      "Epoch 450/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.0254 - mse: 27.9293 - val_loss: 37.1326 - val_mse: 31.0254\n",
      "Epoch 451/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8843 - mse: 28.7855 - val_loss: 37.9274 - val_mse: 31.8223\n",
      "Epoch 452/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.9250 - mse: 28.8272 - val_loss: 46.3572 - val_mse: 40.2329\n",
      "Epoch 453/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.0924 - mse: 28.9990 - val_loss: 38.1769 - val_mse: 32.0708\n",
      "Epoch 454/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8066 - mse: 28.7158 - val_loss: 34.7539 - val_mse: 28.6685\n",
      "Epoch 455/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.0363 - mse: 29.9463 - val_loss: 34.9655 - val_mse: 28.8862\n",
      "Epoch 456/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 33.7514 - mse: 27.6556 - val_loss: 36.8599 - val_mse: 30.7806\n",
      "Epoch 457/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.0705 - mse: 28.9950 - val_loss: 34.3489 - val_mse: 28.2829\n",
      "Epoch 458/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.0084 - mse: 29.9497 - val_loss: 38.2079 - val_mse: 32.1467\n",
      "Epoch 459/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.9049 - mse: 28.8331 - val_loss: 37.7799 - val_mse: 31.7277\n",
      "Epoch 460/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 34.7138 - mse: 28.6536 - val_loss: 35.0610 - val_mse: 29.0025\n",
      "Epoch 461/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 36.5037 - mse: 30.4235 - val_loss: 45.6179 - val_mse: 39.5216\n",
      "Epoch 462/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8692 - mse: 28.7919 - val_loss: 36.1655 - val_mse: 30.0880\n",
      "Epoch 463/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2072 - mse: 29.1384 - val_loss: 36.1129 - val_mse: 30.0311\n",
      "Epoch 464/500\n",
      "354/354 [==============================] - 1s 3ms/step - loss: 34.9667 - mse: 28.8936 - val_loss: 35.5454 - val_mse: 29.4613\n",
      "Epoch 465/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.9185 - mse: 28.8446 - val_loss: 41.9147 - val_mse: 35.8636\n",
      "Epoch 466/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.2537 - mse: 28.1900 - val_loss: 37.7827 - val_mse: 31.7406\n",
      "Epoch 467/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.5587 - mse: 28.5103 - val_loss: 37.0343 - val_mse: 30.9899\n",
      "Epoch 468/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2953 - mse: 29.2409 - val_loss: 35.8151 - val_mse: 29.7746\n",
      "Epoch 469/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.6738 - mse: 28.6266 - val_loss: 37.1905 - val_mse: 31.1285\n",
      "Epoch 470/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.6801 - mse: 28.6187 - val_loss: 36.0168 - val_mse: 29.9628\n",
      "Epoch 471/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.2359 - mse: 29.1703 - val_loss: 38.6905 - val_mse: 32.6333\n",
      "Epoch 472/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.4645 - mse: 28.4091 - val_loss: 35.9071 - val_mse: 29.8653\n",
      "Epoch 473/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8158 - mse: 28.7683 - val_loss: 39.3876 - val_mse: 33.3268\n",
      "Epoch 474/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.7884 - mse: 28.7403 - val_loss: 34.4322 - val_mse: 28.3889\n",
      "Epoch 475/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.4746 - mse: 28.4174 - val_loss: 36.9356 - val_mse: 30.8633\n",
      "Epoch 476/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.0283 - mse: 27.9729 - val_loss: 36.3194 - val_mse: 30.2621\n",
      "Epoch 477/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.0105 - mse: 27.9576 - val_loss: 35.7071 - val_mse: 29.6597\n",
      "Epoch 478/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.6581 - mse: 28.6051 - val_loss: 35.8217 - val_mse: 29.7823\n",
      "Epoch 479/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.7043 - mse: 28.6616 - val_loss: 35.1710 - val_mse: 29.1260\n",
      "Epoch 480/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.3525 - mse: 29.3231 - val_loss: 35.2122 - val_mse: 29.2013\n",
      "Epoch 481/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.4005 - mse: 28.3794 - val_loss: 37.7658 - val_mse: 31.7484\n",
      "Epoch 482/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.6965 - mse: 28.6801 - val_loss: 36.5707 - val_mse: 30.5535\n",
      "Epoch 483/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.7932 - mse: 28.7751 - val_loss: 35.4075 - val_mse: 29.3970\n",
      "Epoch 484/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.5278 - mse: 28.5185 - val_loss: 35.4657 - val_mse: 29.4663\n",
      "Epoch 485/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.7492 - mse: 28.7430 - val_loss: 36.7626 - val_mse: 30.7522\n",
      "Epoch 486/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.2191 - mse: 28.1946 - val_loss: 35.5492 - val_mse: 29.5081\n",
      "Epoch 487/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.5439 - mse: 28.5168 - val_loss: 36.3441 - val_mse: 30.3295\n",
      "Epoch 488/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.0785 - mse: 28.0564 - val_loss: 35.6533 - val_mse: 29.6442\n",
      "Epoch 489/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 33.9225 - mse: 27.9129 - val_loss: 36.8317 - val_mse: 30.8297\n",
      "Epoch 490/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.0367 - mse: 29.0438 - val_loss: 35.9069 - val_mse: 29.8964\n",
      "Epoch 491/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 33.0101 - mse: 27.0133 - val_loss: 36.9776 - val_mse: 30.9523\n",
      "Epoch 492/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8132 - mse: 28.8042 - val_loss: 33.7438 - val_mse: 27.7251\n",
      "Epoch 493/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.4166 - mse: 28.4146 - val_loss: 35.1322 - val_mse: 29.1247\n",
      "Epoch 494/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.8642 - mse: 28.8497 - val_loss: 38.4785 - val_mse: 32.4758\n",
      "Epoch 495/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 35.3041 - mse: 29.2742 - val_loss: 33.8604 - val_mse: 27.8175\n",
      "Epoch 496/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 33.9982 - mse: 27.9613 - val_loss: 35.8114 - val_mse: 29.7595\n",
      "Epoch 497/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.6527 - mse: 28.6274 - val_loss: 36.6237 - val_mse: 30.6209\n",
      "Epoch 498/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 33.9009 - mse: 27.8917 - val_loss: 34.9242 - val_mse: 28.9318\n",
      "Epoch 499/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.2961 - mse: 28.2943 - val_loss: 34.3291 - val_mse: 28.3081\n",
      "Epoch 500/500\n",
      "354/354 [==============================] - 1s 2ms/step - loss: 34.5717 - mse: 28.5597 - val_loss: 39.4295 - val_mse: 33.4270\n"
     ]
    }
   ],
   "source": [
    "a_history_nn = a_model_nn.fit(a_X_nn_train_sc, a_y_nn_train, epochs = 500, verbose = 1, \n",
    "                          validation_data = (a_X_nn_test_sc, a_y_nn_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b6adc2a6-f40b-4657-a166-7c4c4ddec36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#breakfast hour\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "ax[0].plot(a_history_nn.history['loss'], color = 'green')\n",
    "ax[1].plot(a_history_nn.history['val_loss'], color = 'blue')\n",
    "\n",
    "ax[0].set_title('Train')\n",
    "ax[0].set_xlabel('epochs')\n",
    "ax[0].set_ylabel('Loss = MSE')\n",
    "\n",
    "ax[1].set_title('Test')\n",
    "ax[1].set_xlabel('epochs')\n",
    "ax[1].set_ylabel('Loss = MSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7a59700-0e54-4489-b2d9-6ac968862dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 988us/step\n",
      "R^2: 0.9264478033807846\n",
      "Mean Absolute Error: 25.165803909301758\n",
      "Huber Loss: 24.670167922973633\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/towards-data-science/loss-functions-and-their-use-in-neural-networks-a470e703f1e9\n",
    "y_true = a_y_nn_test\n",
    "y_pred = a_model_nn.predict(a_X_nn_test_sc)\n",
    "\n",
    "# R2\n",
    "R2 = metrics.r2_score(a_y_nn_test, a_y_nn_pred)\n",
    "print(f'R^2: {R2}')\n",
    "\n",
    "# MAE\n",
    "mae = MeanAbsoluteError()\n",
    "print(f'Mean Absolute Error: {mae(y_true, y_pred)}')\n",
    "\n",
    "# Huber\n",
    "huber = Huber()\n",
    "print(f'Huber Loss: {huber(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edaf62c-ecf7-4fee-975b-fee70de28981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
