{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a1daa1-84a8-4657-b453-bdeba01f50f7",
   "metadata": {},
   "source": [
    "# Train Data - Average and High\n",
    "Using code from code notebooks 00_1_garmin_gpx.ipynb & 00_2_openweather_api.ipynb to build out the two training datasets for female average performance and high performance. See code notebooks for sources on code. \n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a0b3f-460c-4956-967f-72636f5d8446",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e283b648-308e-41e1-af65-add9eaffa397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# GPX file\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "\n",
    "# GPX file\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "# bearing\n",
    "from geographiclib.geodesic import Geodesic\n",
    "\n",
    "# distance\n",
    "import haversine as hs\n",
    "\n",
    "# API\n",
    "import requests\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21501c17-0148-463a-9650-a2e8941c984f",
   "metadata": {},
   "source": [
    "# Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97d56d-af5c-4f03-ab8f-a002aa52dec1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Historical Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1caca3a4-43fd-4ba9-b32e-f68d5440128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_weather(unix_datetime):\n",
    "    '''\n",
    "    Using the OpenWeather OneCall 3.0 API to pull historical daily data\n",
    "    Input: UNIX datetime for day requesting\n",
    "    Output: Pandas dataframe for that day's weather\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    url_hist_daily = f\"https://api.openweathermap.org/data/3.0/onecall/timemachine?lat=38.752125&lon=-121.288010&dt={unix_datetime}&appid=2f01a2c2a7f1ffcb24807b893d1ba1d2\"\n",
    "    hist_daily_req = requests.get(url_hist_daily)\n",
    "    print(f'API Status: {hist_daily_req.status_code}')\n",
    "\n",
    "    wd_hist = hist_daily_req.json()\n",
    "\n",
    "    wd_hist_df = json_normalize(wd_hist['data'])\n",
    "    wd_hist_df = wd_hist_df[['dt', 'temp', 'feels_like', 'pressure', 'humidity',\n",
    "           'dew_point', 'uvi', 'clouds', 'visibility', 'wind_speed', 'wind_deg']]\n",
    "\n",
    "    # Convert dt UNIX to datetime UTC\n",
    "    wd_hist_df['dt'] = wd_hist_df['dt'].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "    \n",
    "    return wd_hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f44693-2e0e-4284-aa53-1762df70250d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPX to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9bfd149-3de0-43bf-9286-e1c8d6241bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpx_to_df(filepath):\n",
    "    \n",
    "    # Open .gpx file and parse xml\n",
    "    with open(filepath, 'r') as gpx_file:\n",
    "        gpx = gpxpy.parse(gpx_file)\n",
    "        \n",
    "    # check length of tracks\n",
    "    print(f'Tracks: {len(gpx.tracks)}')\n",
    "    # check number of data points\n",
    "    print(f'No. of Track Points: {gpx.get_track_points_no()}')\n",
    "    \n",
    "    # extract timestamp, lat, lon, and elevation from gpx file\n",
    "    route_info = []\n",
    "\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                route_info.append({\n",
    "                    'timestamp': point.time,\n",
    "                    'latitude': point.latitude,\n",
    "                    'longitude': point.longitude,\n",
    "                    'elevation': point.elevation,\n",
    "                })\n",
    "    \n",
    "    # create dataframe\n",
    "    route_df = pd.DataFrame(route_info)\n",
    "    \n",
    "    #######################\n",
    "    # HEART RATE AND CADENCE\n",
    "    # add extension data with beautifulsoup\n",
    "    xml = gpx.to_xml()\n",
    "    soup = BeautifulSoup(xml, features = 'xml')\n",
    "    \n",
    "    # Use Beautiful Soup to find all heart rate and cadence\n",
    "    hr_soup = soup.find_all('ns3:hr')\n",
    "    cad_soup = soup.find_all('ns3:cad')\n",
    "    \n",
    "    # chop off early points from index - accounts for before cadence sensor calibration\n",
    "    route_df = route_df[-len(cad_soup):]\n",
    "\n",
    "    # for loop to extract heart rate and cadence values from each point\n",
    "    hr_list = []\n",
    "    cad_list = []\n",
    "    for i in hr_soup:\n",
    "        # https://stackoverflow.com/questions/69420686/bs4-element-resultset-elements-to-a-list\n",
    "        hr_list.append(i.get_text(strip = True))\n",
    "\n",
    "    for j in cad_soup:\n",
    "        cad_list.append(j.get_text(strip = True))\n",
    "\n",
    "    # add columns to dataset from extraction\n",
    "    route_df['heart_rate'] = hr_list[-len(cad_soup):]\n",
    "    route_df['cadence'] = cad_list\n",
    "    \n",
    "    #######################\n",
    "    # BEARING\n",
    "    # get_bearing function\n",
    "    def get_bearing(lat1, lat2, long1, long2):\n",
    "        brng = Geodesic.WGS84.Inverse(lat1, long1, lat2, long2)['azi1']\n",
    "        return brng\n",
    "    \n",
    "    # assign bearing in df\n",
    "    route_df['bearing'] = 0\n",
    "    for i in range(1, len(route_df)):\n",
    "        lat1 = route_df.latitude.iloc[i-1]\n",
    "        lat2 = route_df.latitude.iloc[i]\n",
    "        long1 = route_df.longitude.iloc[i-1]\n",
    "        long2 = route_df.longitude.iloc[i]\n",
    "        bearing = get_bearing(lat1, lat2, long1, long2)\n",
    "        # https://stats.stackexchange.com/questions/283572/using-iloc-to-set-values\n",
    "        route_df.bearing.iloc[[i]] = bearing\n",
    "    \n",
    "    ########################    \n",
    "    # ELAPSED TIME - SECONDS\n",
    "    route_df['timestamp'] = pd.to_datetime(route_df['timestamp'])\n",
    "    route_df['time_diff_s'] = 0\n",
    "    for i in range(1, len(route_df)-1):\n",
    "        t1 = route_df.iloc[i]['timestamp']\n",
    "        t2 = route_df.iloc[i-1]['timestamp']\n",
    "        # https://www.geeksforgeeks.org/how-to-set-cell-value-in-pandas-dataframe/\n",
    "        route_df.at[i, 'time_diff_s'] = (t1 - t2).seconds\n",
    "    route_df['total_time_s'] = route_df['time_diff_s'].cumsum(skipna = True)\n",
    "    \n",
    "    #######################\n",
    "    # ELEVATION CHANGE - METERS\n",
    "    route_df['ele_diff'] = 0\n",
    "    for i in range(1, len(route_df)-1):\n",
    "        e1 = route_df.iloc[i]['elevation']\n",
    "        e2 = route_df.iloc[i-1]['elevation']\n",
    "        route_df.at[i, 'ele_diff'] = (e1 - e2)\n",
    "    route_df['total_ele_change'] = round(route_df['ele_diff'].cumsum(skipna = True), 4)\n",
    "    \n",
    "    #######################\n",
    "    # DISTANCE - KILOMETERS\n",
    "    route_df['lat_lon'] = [(lat, lon) for lat, lon in zip(route_df['latitude'], route_df['longitude'])]\n",
    "    route_df['dist_diff_km'] = 0\n",
    "    for i in range(1, len(route_df)-1):\n",
    "        loc1 = route_df.iloc[i]['lat_lon']\n",
    "        loc2 = route_df.iloc[i-1]['lat_lon']\n",
    "        route_df.at[i, 'dist_diff_km'] = round(hs.haversine(loc1, loc2), 4) # kilometers\n",
    "    route_df['total_dist_km'] = route_df['dist_diff_km'].cumsum(skipna = True)\n",
    "   \n",
    "    #######################\n",
    "    route_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return route_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c0081-74c3-4488-8ec8-5ce933a95de1",
   "metadata": {},
   "source": [
    "# Average Cycling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afedcfb3-73cf-4f02-a8a2-0b5344839cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracks: 1\n",
      "No. of Track Points: 400\n",
      "Tracks: 1\n",
      "No. of Track Points: 3015\n",
      "Tracks: 1\n",
      "No. of Track Points: 853\n",
      "Tracks: 1\n",
      "No. of Track Points: 1333\n",
      "Tracks: 1\n",
      "No. of Track Points: 157\n",
      "Tracks: 1\n",
      "No. of Track Points: 2224\n",
      "Tracks: 1\n",
      "No. of Track Points: 1364\n",
      "Tracks: 1\n",
      "No. of Track Points: 1070\n",
      "Tracks: 1\n",
      "No. of Track Points: 739\n",
      "Tracks: 1\n",
      "No. of Track Points: 181\n",
      "Tracks: 1\n",
      "No. of Track Points: 1453\n",
      "Tracks: 1\n",
      "No. of Track Points: 2304\n"
     ]
    }
   ],
   "source": [
    "average = dict()\n",
    "\n",
    "for x in range(1, 13):\n",
    "    average[x] = gpx_to_df(f'../data/average/a_{x}.gpx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8768854e-3609-42fb-ba2e-10f0759f2992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38.63356165587902, -121.21797876432538)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average[2]['lat_lon'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190cbea5-abfc-4bd4-af18-8ee8bc01f8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
