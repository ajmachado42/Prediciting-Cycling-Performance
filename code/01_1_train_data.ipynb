{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63a1daa1-84a8-4657-b453-bdeba01f50f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TRAIN DATA\n",
    "---\n",
    "---\n",
    "### *Using code from code notebooks 00_1_garmin_gpx.ipynb & 00_2_openweather_api.ipynb to build out the two training datasets for female average performance and high performance. See code notebooks for sources on code.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a0b3f-460c-4956-967f-72636f5d8446",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e283b648-308e-41e1-af65-add9eaffa397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# GPX file\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "\n",
    "# GPX file\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "\n",
    "# bearing\n",
    "from geographiclib.geodesic import Geodesic\n",
    "\n",
    "# distance\n",
    "import haversine as hs\n",
    "\n",
    "# API\n",
    "import requests\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10eecd6d-a762-42a4-8e1e-238ca00c3259",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = [REDACTED]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21501c17-0148-463a-9650-a2e8941c984f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97d56d-af5c-4f03-ab8f-a002aa52dec1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Historical Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1caca3a4-43fd-4ba9-b32e-f68d5440128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_weather(unix_datetime, lat, lon, API_key = API_key):\n",
    "    '''\n",
    "    Using the OpenWeather OneCall 3.0 API to pull historical daily data\n",
    "    Requires API key for at minimum Startup OpenWeather subscription\n",
    "    Input: UNIX datetime for day requesting\n",
    "    Output: Pandas dataframe for that historical datetime's weather\n",
    "    '''\n",
    "    \n",
    "    url_hist_point = f\"https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={unix_datetime}&appid={API_key}\"\n",
    "    hist_point_req = requests.get(url_hist_point)\n",
    "\n",
    "    wd_hist = hist_point_req.json()\n",
    "\n",
    "    wd_hist_df = json_normalize(wd_hist['data'])\n",
    "    wd_hist_df = wd_hist_df[['dt', 'temp', 'feels_like', 'pressure', 'humidity',\n",
    "           'dew_point', 'clouds', 'wind_speed', 'wind_deg']]\n",
    "\n",
    "    \n",
    "    return wd_hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f44693-2e0e-4284-aa53-1762df70250d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GPX to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bfd149-3de0-43bf-9286-e1c8d6241bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpx_to_df(filepath):\n",
    "    \n",
    "    # Open .gpx file and parse xml\n",
    "    with open(filepath, 'r') as gpx_file:\n",
    "        gpx = gpxpy.parse(gpx_file)\n",
    "        \n",
    "    # check file\n",
    "    print(f'File: {filepath}')\n",
    "    # check length of tracks\n",
    "    print(f'Tracks: {len(gpx.tracks)}')\n",
    "    # check number of data points\n",
    "    print(f'No. of Track Points: {gpx.get_track_points_no()}')\n",
    "    \n",
    "    # extract timestamp, lat, lon, and elevation from gpx file\n",
    "    route_info = []\n",
    "\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                route_info.append({\n",
    "                    'timestamp': point.time,\n",
    "                    'latitude': point.latitude,\n",
    "                    'longitude': point.longitude,\n",
    "                    'elevation': point.elevation,\n",
    "                })\n",
    "    \n",
    "    # create dataframe\n",
    "    route_df = pd.DataFrame(route_info)\n",
    "    # create UNIX column for later\n",
    "    # https://statisticsglobe.com/convert-datetime-to-unix-timestamp-python\n",
    "    route_df['dt'] = route_df['timestamp'].apply(lambda z: int(datetime.datetime.timestamp(z)))\n",
    "    \n",
    "    #######################\n",
    "    # HEART RATE - REMOVED CADENCE DUE TO LACK OF SENSOR DATA EARLIER THIS YEAR\n",
    "    # add extension data with beautifulsoup\n",
    "    xml = gpx.to_xml()\n",
    "    soup = BeautifulSoup(xml, features = 'xml')\n",
    "    \n",
    "    # Use Beautiful Soup to find all heart rate\n",
    "    hr_soup = soup.find_all('ns3:hr')\n",
    "\n",
    "    # for loop to extract heart rate and cadence values from each point\n",
    "    hr_list = []\n",
    "    for i in hr_soup:\n",
    "        # https://stackoverflow.com/questions/69420686/bs4-element-resultset-elements-to-a-list\n",
    "        hr_list.append(i.get_text(strip = True))\n",
    "\n",
    "    # add columns to dataset from extraction\n",
    "    route_df['heart_rate'] = hr_list\n",
    "    \n",
    "    #######################\n",
    "    # BEARING\n",
    "    # get_bearing function\n",
    "    def get_bearing(lat1, lat2, long1, long2):\n",
    "        brng = Geodesic.WGS84.Inverse(lat1, long1, lat2, long2)['azi1']\n",
    "        return brng\n",
    "    \n",
    "    # assign bearing in df\n",
    "    route_df['bearing'] = 0\n",
    "    for i in range(1, len(route_df)):\n",
    "        lat1 = route_df.latitude.iloc[i-1]\n",
    "        lat2 = route_df.latitude.iloc[i]\n",
    "        long1 = route_df.longitude.iloc[i-1]\n",
    "        long2 = route_df.longitude.iloc[i]\n",
    "        bearing = get_bearing(lat1, lat2, long1, long2)\n",
    "        # https://stats.stackexchange.com/questions/283572/using-iloc-to-set-values\n",
    "        route_df.bearing.iloc[[i]] = bearing\n",
    "    \n",
    "    ########################    \n",
    "    # ELAPSED TIME - SECONDS\n",
    "    route_df['timestamp'] = pd.to_datetime(route_df['timestamp'])\n",
    "    route_df['time_diff_s'] = 0\n",
    "    for i in range(1, len(route_df)-1):\n",
    "        t1 = route_df.iloc[i]['timestamp']\n",
    "        t2 = route_df.iloc[i-1]['timestamp']\n",
    "        # https://www.geeksforgeeks.org/how-to-set-cell-value-in-pandas-dataframe/\n",
    "        route_df.at[i, 'time_diff_s'] = (t1 - t2).seconds\n",
    "    route_df['total_time_s'] = route_df['time_diff_s'].cumsum(skipna = True)\n",
    "    \n",
    "    #######################\n",
    "    # ELEVATION CHANGE - METERS\n",
    "    route_df['ele_diff_m'] = 0\n",
    "    for i in range(1, len(route_df)-1):\n",
    "        e1 = route_df.iloc[i]['elevation']\n",
    "        e2 = route_df.iloc[i-1]['elevation']\n",
    "        route_df.at[i, 'ele_diff_m'] = (e1 - e2)\n",
    "    route_df['total_ele_change_m'] = round(route_df['ele_diff_m'].cumsum(skipna = True), 4)\n",
    "    \n",
    "    #######################\n",
    "    # DISTANCE - KILOMETERS\n",
    "    route_df['lat_lon'] = [(lat, lon) for lat, lon in zip(route_df['latitude'], route_df['longitude'])]\n",
    "    route_df['dist_diff_km'] = 0\n",
    "    for i in range(1, len(route_df)-1):\n",
    "        loc1 = route_df.iloc[i]['lat_lon']\n",
    "        loc2 = route_df.iloc[i-1]['lat_lon']\n",
    "        route_df.at[i, 'dist_diff_km'] = round(hs.haversine(loc1, loc2), 4) # kilometers\n",
    "    route_df['total_dist_km'] = route_df['dist_diff_km'].cumsum(skipna = True)\n",
    "    \n",
    "   \n",
    "    #######################\n",
    "    route_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    return route_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8c0081-74c3-4488-8ec8-5ce933a95de1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Average Cycling Performance Period Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081579f5-9664-4759-b558-f671435cfe95",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get GPX files and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3f31c3-e8b4-4393-a051-5ab2a58bf197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#https://stackoverflow.com/questions/13603215/using-a-loop-in-python-to-name-variables\\naverage = dict()\\n \\nfor x in range(1, 13): # number of files\\n    average[x] = gpx_to_df(f'../data/average/a_{x}.gpx')\\n\\na_df = pd.concat(average)\\na_df.dropna(inplace = True)\\n# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\\na_df.reset_index(inplace = True, level = [0,1], drop = True)\\n\\nprint()\\nprint(f'Size of a_df: {a_df.shape}')\\nprint()\\n\\na_df.head()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#https://stackoverflow.com/questions/13603215/using-a-loop-in-python-to-name-variables\n",
    "average = dict()\n",
    " \n",
    "for x in range(1, 13): # number of files\n",
    "    average[x] = gpx_to_df(f'../data/average/a_{x}.gpx')\n",
    "\n",
    "a_df = pd.concat(average)\n",
    "a_df.dropna(inplace = True)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
    "a_df.reset_index(inplace = True, level = [0,1], drop = True)\n",
    "\n",
    "print()\n",
    "print(f'Size of a_df: {a_df.shape}')\n",
    "print()\n",
    "\n",
    "a_df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873c9d5-cce2-4465-b2ac-96ab656229d9",
   "metadata": {},
   "source": [
    "## Get historical weather and join with average dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ecb2ea-c3bc-4f92-b924-65472966eb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>clouds</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_deg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1658333265</td>\n",
       "      <td>298</td>\n",
       "      <td>297.53</td>\n",
       "      <td>1017</td>\n",
       "      <td>38</td>\n",
       "      <td>282.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  temp  feels_like  pressure  humidity  dew_point  clouds  \\\n",
       "0  1658333265   298      297.53      1017        38     282.73       1   \n",
       "\n",
       "   wind_speed  wind_deg  \n",
       "0        0.45       177  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_weather(1658333265, 38.752125, -121.288010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190cbea5-abfc-4bd4-af18-8ee8bc01f8a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\na_weather = pd.DataFrame()\\n\\nfor i in range(len(a_df)): # iterate through each trackpoint\\n    # 600 calls per minute\\n    unix = a_df['dt'][i]\\n    lat = a_df['latitude'][i]\\n    lon = a_df['longitude'][i]\\n    weather = hist_weather(unix, lat, lon) # get historical weather for trackpoint\\n    a_weather = a_weather.append(weather) # append to weather dataframe\\n        \\na_df = a_df.merge(a_weather, how = 'inner', on = 'dt') # merge activity dataframe with weather dataframe on unix time stamp\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "a_weather = pd.DataFrame()\n",
    "\n",
    "for i in range(len(a_df)): # iterate through each trackpoint\n",
    "    # 600 calls per minute\n",
    "    unix = a_df['dt'][i]\n",
    "    lat = a_df['latitude'][i]\n",
    "    lon = a_df['longitude'][i]\n",
    "    weather = hist_weather(unix, lat, lon) # get historical weather for trackpoint\n",
    "    a_weather = a_weather.append(weather) # append to weather dataframe\n",
    "        \n",
    "a_df = a_df.merge(a_weather, how = 'inner', on = 'dt') # merge activity dataframe with weather dataframe on unix time stamp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a15c7b-7579-4791-b312-554ea333d6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d32a65-b853-4307-a734-a12e0bb1e807",
   "metadata": {
    "tags": []
   },
   "source": [
    "# High Cycling Performance Period Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2939cd-b7bd-48b0-83a3-29abdb39bb48",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get GPX files and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e99225-b3fe-406f-945b-b1e27e39b156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#https://stackoverflow.com/questions/13603215/using-a-loop-in-python-to-name-variables\\nhigh = dict()\\n\\nfor x in range(1, 17): # number of files\\n    high[x] = gpx_to_df(f'../data/high/h_{x}.gpx')\\n\\nh_df = pd.concat(high)\\nh_df.dropna(inplace = True)\\nh_df.reset_index(inplace = True, level = [0,1], drop = True)\\nprint()\\nprint(f'Size of h_df: {h_df.shape}')\\nprint()\\nh_df.head()\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#https://stackoverflow.com/questions/13603215/using-a-loop-in-python-to-name-variables\n",
    "high = dict()\n",
    "\n",
    "for x in range(1, 17): # number of files\n",
    "    high[x] = gpx_to_df(f'../data/high/h_{x}.gpx')\n",
    "\n",
    "h_df = pd.concat(high)\n",
    "h_df.dropna(inplace = True)\n",
    "h_df.reset_index(inplace = True, level = [0,1], drop = True)\n",
    "print()\n",
    "print(f'Size of h_df: {h_df.shape}')\n",
    "print()\n",
    "h_df.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356dcae4-740b-4821-897b-a5da9178ff92",
   "metadata": {},
   "source": [
    "## Get historical weather and join with high dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9794361-eb38-4b7c-82f4-133c4c00b78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nh_weather = pd.DataFrame()\\n\\nfor i in range(len(h_df)): # iterate through each trackpoint\\n    # 600 calls per minute\\n    unix = h_df['dt'][i]\\n    lat = h_df['latitude'][i]\\n    lon = h_df['longitude'][i]\\n    weather = hist_weather(unix, lat, lon) # get historical weather for trackpoint\\n    h_weather = h_weather.append(weather) # append to weather dataframe\\n        \\nh_df = h_df.merge(h_weather, how = 'inner', on = 'dt') # merge activity dataframe with weather dataframe on unix time stamp\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "h_weather = pd.DataFrame()\n",
    "\n",
    "for i in range(len(h_df)): # iterate through each trackpoint\n",
    "    # 600 calls per minute\n",
    "    unix = h_df['dt'][i]\n",
    "    lat = h_df['latitude'][i]\n",
    "    lon = h_df['longitude'][i]\n",
    "    weather = hist_weather(unix, lat, lon) # get historical weather for trackpoint\n",
    "    h_weather = h_weather.append(weather) # append to weather dataframe\n",
    "        \n",
    "h_df = h_df.merge(h_weather, how = 'inner', on = 'dt') # merge activity dataframe with weather dataframe on unix time stamp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eabeff89-5040-4213-a320-ca45a1c215d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c751ca45-15cb-4e67-bd50-4dc440a479f5",
   "metadata": {},
   "source": [
    "# Save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5ef7ad2-c104-426d-8033-43fb178e48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_df.to_csv('../data/average/a_df.csv', index = False)\n",
    "# h_df.to_csv('../data/high/h_df.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721beea-19b1-48ac-845e-c0f0068f9305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
